# Python CircleCI 2.1 configuration file
#
# Check https://circleci.com/docs/2.2/language-python/ for more details

master_and_release_only: &master_and_release_only
  filters:
    branches:
      only:
        - master
        - release
        # Those short lived branches are automatically created by our StackStorm build automation
        # so we can ensure all the jobs (including the ones which only run on master) pass before
        # merging a PR.
        - /automated_tests\/.*/

# NOTE: We intentionally don't want benchmarks to run on automated_tests/ branches.
benchmarks_master_and_release_only: &benchmarks_master_and_release_only
  filters:
    branches:
      only:
        - master
        - release

master_only: &master_only
  filters:
    branches:
      only:
        - master
        - improve_coverage
        # Those short lived branches are automatically created by our StackStorm build automation
        # so we can ensure all the jobs (including the ones which only run on master) pass before
        # merging a PR.
        - /automated_tests\/.*/

non_master_and_release: &non_master_and_release
  filters:
    branches:
      ignore:
        - master
        - release
        # Those short lived branches are automatically created by our StackStorm build automation
        # so we can ensure all the jobs (including the ones which only run on master) pass before
        # merging a PR.
        - /automated_tests\/.*/

# the "release_build" branch is used in the release process and should be triggered only through CircleCI API
# so, we skip triggering from regular git push.
skip_release_build_branch_push: &skip_release_build_branch_push
  unless:
    and:
      - equal: [ false, << pipeline.parameters.is_release_build >>]
      - equal: [ release_build,  << pipeline.git.branch >>]

version: 2.1

orbs:
  slack: circleci/slack@3.4.2
  win: circleci/windows@2.4.0

# Global workflow level parameters
parameters:
  default_tox_version:
    type: string
    default: "3.20.1"
  default_pip_version:
    type: string
    default: "20.0.2"
  cache_version_docker_images:
    description: "Cache version suffix used for all the Docker image caches."
    type: string
    default: "v16"
  cache_version_py_dependencies:
    description: "Cache version suffix used for all the Python dependency caches."
    type: string
    default: "v7"
  is_release_build:
    description: "Only true when the pipeline is triggered for the release."
    type: boolean
    default: false
  agent_version:
    description: "The version of the packages which are built by specific jobs. It remains the same as in VERSION file if this parameter is empty."
    type: string
    default: ""
  release_repo_name:
    description: "The name of the target release S3 repo."
    type: string
    default: ""
  release_repo_base_url:
    description: "Build artifacts path in S3 repo."
    type: string
    default: ""

commands:
  unittest_tox:
    description: "A base command for all tox based unit test jobs"
    parameters:
      python_version:
        description: "Python version to use (e.g. 3.5, 3.6, 3.7, 3.8, etc.)."
        type: string
      tox_version:
        description: "tox package version to use."
        type: string
        default: "3.20.1"
      apt_dependencies:
        description: "Any optional apt dependencies which should be installed."
        type: string
        default: ""
      tox_target:
        description: "Tox target to run."
        type: string
      upload_coverage:
        description: "True to combine and upload coverage data to codecov.io."
        type: boolean
        default: false
    steps:
      - checkout
      - restore_cache:
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-tox-{{ .Branch }}-<< parameters.python_version >>-venv-{{ checksum "dev-requirements.txt" }}-{{ checksum "agent_build/requirement-files/compression-requirements.txt" }}-{{ checksum "agent_build/requirement-files/testing-requirements.txt" }}
      - when:
          condition: << parameters.apt_dependencies >>
          steps:
            - run:
                name: Install APT Dependencies
                command: |
                  apt-get update -y
                  apt-get install -y << parameters.apt_dependencies >>
      - run:
          name: Install Dependencies
          command: |
            pip install "tox==<< parameters.tox_version >>"
      - run:
          name: Run Unit Tests under Python << parameters.python_version >>
          command: |
            tox -e<< parameters.tox_target >>
      - save_cache:
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-tox-{{ .Branch }}-<< parameters.python_version >>-venv-{{ checksum "dev-requirements.txt" }}-{{ checksum "agent_build/requirement-files/compression-requirements.txt" }}-{{ checksum "agent_build/requirement-files/testing-requirements.txt" }}
          paths:
            - "~/.cache/pip"
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test-results
      - when:
          condition: << parameters.upload_coverage >>
          steps:
            - run:
                name: Submit Coverage Data to codecov.io and Combine it and Upload it to S3
                command: |
                  ls -la .coverage* || true

                  pip install "coverage==4.5.4" "codecov==2.1.3" "apache-libcloud==2.8.3"
                  cp .circleci/.coveragerc_ci .coveragerc

                  # Print the report
                  coverage report -i

                  # Submit it to codecov.io
                  coverage xml --rcfile=.coveragerc -i -o coverage.xml
                  ./scripts/submit-codecov-data.sh

                  # Combine it and upload it to S3
                  coverage combine || true
                  export PYTHONPATH=.
                  ./scripts/circleci/upload-coverage-data-to-s3.py ".coverage"

  codespeed_agent_process_benchmark:
    description: "A base command which runs CodeSpeed agent process level benchmarks"
    parameters:
      codespeed_executable:
        description: "CodeSpeed executable name."
        type: string
      codespeed_environment:
        description: "CodeSpeed environment name."
        type: string
        default: "Circle CI Docker Executor Medium Size"
      agent_config:
        description: "Path to the agent config file to use."
        type: string
      run_time:
        description: "How long to run the capture for (in seconds)."
        type: integer
        default: 120
      capture_interval:
        description: "How often to capture agent process level metrics during the process run time (in seconds)."
        type: integer
        default: 5
      agent_pre_run_command:
        description: "Optional bash command / script to run before starting the agent and the metrics capture script."
        type: string
        default: ""
      agent_post_run_command:
        description: "Optional bash command / script to run after starting the agent and the metrics capture script."
        type: string
        default: ""
      agent_server_host:
        description: "Value for the server_attributes.serverHost agent configuration option."
        type: string
        default: "ci-codespeed-benchmarks"
      capture_agent_status_metrics:
        description: "True to capture additional metrics exposed via agent status command."
        type: boolean
        default: false
      capture_line_counts:
        description: "True to submit log line counts for each log level to CodeSpeed."
        type: boolean
        default: false
      dry_run:
        description: "True to enable dry run which runs the benchmarks without submitting data to CodeSpeed."
        type: boolean
        default: false
      cache_key_name:
        description: "Circle CI cache key name"
        type: string
        default: "Circle CI cache key name"
    steps:
      - checkout
      - restore_cache:
          key: deps1-{{ .Branch }}-<< parameters.cache_key_name >>-venv-{{ checksum "benchmarks/scripts/requirements.txt" }}
      - run:
          name: Install Dependencies
          command: |
            pip install --user -r benchmarks/scripts/requirements.txt

            # Workaround for issue with cffi library on the system using
            # different version than the one which is bundled with the agent
            pip install --user "cffi==1.12.3"
      - run:
          name: Run Agent And Capture Resource Utilization
          # NOTE: The following variables are specified in the Circle CI WebUI
          # and are handles as secrets: CODESPEED_AUTH
          environment:
            CODESPEED_URL: "https://scalyr-agent-codespeed.herokuapp.com/"
            CODESPEED_PROJECT: "scalyr-agent-2-procbenchmarks"
            CODESPEED_EXECUTABLE: "<< parameters.codespeed_executable >>"
            CODESPEED_ENVIRONMENT: "<< parameters.codespeed_environment >>"
            CODESPEED_BRANCH: "${CIRCLE_BRANCH}"
            # NOTE: "idle" agent process (which monitors no logs but just runs the linux process
            # monitor for the agent process) should stabilize in a couple of minutes so it makes
            # no sense to run that benchmark longer.
            RUN_TIME: << parameters.run_time >>
            CAPTURE_INTERVAL: << parameters.capture_interval >>
            AGENT_CONFIG_FILE: "<< parameters.agent_config >>"
            SCALYR_SERVER_ATTRIBUTES: "{\"serverHost\": \"<< parameters.agent_server_host>>\"}"
            CAPTURE_AGENT_STATUS_METRICS: "<< parameters.capture_agent_status_metrics >>"
            DRY_RUN: "<< parameters.dry_run >>"
          command: |
            # Create directories which are needed by the agent process
            mkdir -p ~/scalyr-agent-dev/{log,config,data}

            # NOTE: We explicitly specify a commit date to avoid CodeSpeed from
            # late setting the actual date once it fetches all the commits for a
            # branch / revision
            export TZ=UTC
            export COMMIT_DATE=$(git show --quiet --date='format-local:%Y-%m-%d %H:%M:%S' --format="%cd" ${CIRCLE_SHA1})
            export PYTHONPATH=.

            # Run any pre agent run script (if defined)
            if [ ! -z "<< parameters.agent_pre_run_command >>" ]; then
                echo "Running agent pre run command..."
                << parameters.agent_pre_run_command >>
            fi

            # Run the agent process and capture the metrics
            ./benchmarks/scripts/start-agent-and-capture-metrics.sh "${CIRCLE_SHA1}" &> /tmp/capture_script.log &
            CAPTURE_SCRIPT_PID=$!

            # Run any post agent run script (if defined)
            # NOTE: We intentionally sleep for a bit to give agent time to fully
            # start up
            if [ ! -z "<< parameters.agent_post_run_command >>" ]; then
                echo "Running agent post run command..."
                sleep 2
                << parameters.agent_post_run_command >>
            fi

            # Wait for capture script to finish
            set +e
            sh -c 'tail -n +0 -F /tmp/capture_script.log | { sed "/Run completed, stopping the agent process./ q" && kill $$ ;}'
            wait ${CAPTURE_SCRIPT_PID} || true
            set -e

            # Send line count values for various log levels (if enabled)
            if [ "<< parameters.capture_line_counts >>" = "true" ]; then
                ./benchmarks/scripts/send-log-level-counts-to-codespeed.sh "${CIRCLE_SHA1}"
            fi
      - save_cache:
          key: deps1-{{ .Branch }}-<< parameters.cache_key_name >>-venv-{{ checksum "benchmarks/scripts/requirements.txt" }}
          paths:
            - "~/.cache/pip"
      # NOTE: We store the logs to ease with troubleshooting / debugging
      - store_artifacts:
          path: ~/scalyr-agent-dev/log
      - slack/status:
          fail_only: true
          only_for_branches: master

  codespeed_micro_benchmarks:
    description: "A base command which runs CodeSpeed code-level micro benchmarks"
    parameters:
      tox_version:
        description: "tox package version to use."
        type: string
        default: "3.20.1"
      codespeed_executable:
        description: "CodeSpeed executable name."
        type: string
      codespeed_environment:
        description: "CodeSpeed environment name."
        type: string
        default: "Circle CI Docker Executor Medium Size"
      cache_key_name:
        description: "Circle CI cache key name"
        type: string
        default: "none"
    steps:
      - checkout
      - run:
          name: "Checkout Log Fixture Files Submodule"
          command: |
            git submodule init
            git submodule update --remote
      - restore_cache:
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-{{ .Branch }}-<< parameters.cache_key_name >>-venv-{{ checksum "dev-requirements.txt" }}-{{ checksum "benchmarks/scripts/requirements.txt" }}
      - run:
          name: Install Dependencies
          command: |
            pip install "tox==<< parameters.tox_version >>"

            # Workaround for issue with cffi library on the system using
            # different version than the one which is bundled with the agent
            pip install --user "cffi==1.12.3"
            # Add udatetime which is needed by send_microbenchmarks_data_to_codespeed.py
            pip install --user "udatetime==0.0.16"

            pip install --user "requests"

            # Needed for snappy library
            sudo apt-get update
            sudo apt-get install -y libsnappy-dev
      - run:
          name: Run Micro Benchmarks
          # NOTE: The following variables are specified in the Circle CI WebUI
          # and are handles as secrets: CODESPEED_AUTH
          environment:
            CODESPEED_URL: "https://scalyr-agent-codespeed.herokuapp.com/"
            CODESPEED_PROJECT: "scalyr-agent-2-microbenchmarks"
            CODESPEED_EXECUTABLE: "<< parameters.codespeed_executable >>"
            CODESPEED_ENVIRONMENT: "<< parameters.codespeed_environment >>"
          command: |
            # Run benchmarks
            tox -emicro-benchmarks

            # Process and submit results to CodeSpeed
            if [[ "${CIRCLE_BRANCH}" == "master" ]]; then
              export PYTHONPATH=.
              python benchmarks/scripts/send_microbenchmarks_data_to_codespeed.py \
                  --data-path="benchmark_results/*.json" \
                  --debug
            fi
      - store_artifacts:
          path: ~/scalyr-agent-2/benchmark_results/
      - store_artifacts:
          path: ~/scalyr-agent-2/benchmark_histograms/
      - save_cache:
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-{{ .Branch }}-<< parameters.cache_key_name >>-venv-{{ checksum "dev-requirements.txt" }}-{{ checksum "benchmarks/scripts/requirements.txt" }}
          paths:
            - "~/.cache/pip"
      - slack/status:
          fail_only: true
          only_for_branches: master

  smoke-standalone-tox:
    description: "A base command for all tox based smoke test jobs"
    parameters:
      python_version:
        description: "Python version to use (e.g. 3.5, 3.6, 3.7, 3.8, etc.)."
        type: string
      tox_version:
        description: "tox package version to use."
        type: string
        default: "3.20.1"
      pre_checkout_apt_dependencies:
        description: "Any optional apt dependencies which are installed before checkout step."
        type: string
        default: ""
      apt_dependencies:
        description: "Any optional apt dependencies which should be installed."
        type: string
        default: ""
      tox_target:
        description: "Tox target to run."
        type: string
    steps:
      - when:
          condition: << parameters.pre_checkout_apt_dependencies >>
          steps:
            - run:
                name: Install APT Dependencies (pre checkout)
                command: |
                  apt-get update -y
                  apt-get install -y << parameters.pre_checkout_apt_dependencies >>
      - checkout
      - restore_cache:
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-tox-{{ .Branch }}-<< parameters.python_version >>-venv-{{ checksum "dev-requirements.txt" }}
      - when:
          condition: << parameters.apt_dependencies >>
          steps:
            - run:
                name: Install APT Dependencies
                command: |
                  apt-get update -y
                  apt-get install -y << parameters.apt_dependencies >>
      - run:
          name: Install Dependencies
          command: |
            pip install "tox==<< parameters.tox_version >>"
      - run:
          name: Run Unit Tests under Python << parameters.python_version >>
          command: |
            # Concatenate 'CIRCLE_BUILD_NUM' and 'AGENT_HOST_NAME' env. variables.
            # when job runs from CircleCi servers, the 'AGENT_HOST_NAME' is not set, so 'CIRCLE_BUILD_NUM' is used.
            # when job runs locally, the 'CIRCLE_BUILD_NUM' is not set, so 'AGENT_HOST_NAME' is used.
            export CIRCLE_BUILD_NUM=${CIRCLE_BUILD_NUM}${AGENT_HOST_NAME}
            export AGENT_HOST_NAME=agent-smoke-standalone-<< parameters.python_version >>-${CIRCLE_BUILD_NUM}

            tox -e<< parameters.tox_target >>
      - save_cache:
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-tox-{{ .Branch }}-<< parameters.python_version >>-venv-{{ checksum "dev-requirements.txt" }}
          paths:
            - "~/.cache/pip"

      # NOTE: We store the logs to ease with troubleshooting / debugging
      - store_artifacts:
          path: ~/scalyr-agent-dev/log

      - slack/status:
          fail_only: true
          only_for_branches: master

  run-tox-target:
    description: "Base command which runs the specified tox target."
    parameters:
      agent_host_name:
        type:
          string
      target_name:
        type:
          string
      upload_coverage:
        description: "True to combine and upload coverage data to codecov.io."
        type: boolean
        default: false
    steps:
      - run:
          name: "Run tox target: << parameters.target_name >>"
          command: |
            # Concatenate 'CIRCLE_BUILD_NUM' and 'AGENT_HOST_NAME' env. variables.
            # when job runs from CircleCi servers, the 'AGENT_HOST_NAME' is not set, so 'CIRCLE_BUILD_NUM' is used.
            # when job runs locally, the 'CIRCLE_BUILD_NUM' is not set, so 'AGENT_HOST_NAME' is used.
            export CIRCLE_BUILD_NUM=${CIRCLE_BUILD_NUM}${AGENT_HOST_NAME}
            echo << parameters.agent_host_name >>
            export AGENT_HOST_NAME=<< parameters.agent_host_name >>-${CIRCLE_BUILD_NUM}
            echo "Using agent hostname: ${AGENT_HOST_NAME}"
            mkdir -p ~/artifacts

            tox -e << parameters.target_name >> -- --no-rebuild --artifacts-path ~/artifacts -n 2

      # NOTE: We store the logs to ease with troubleshooting / debugging
      - store_artifacts:
          path: ~/artifacts

      - when:
          condition: << parameters.upload_coverage >>
          steps:
            - run:
                name: Submit Coverage Data to codecov.io and Combine it and Upload it to S3
                command: |
                  # Also copy over .coverage file from tests (aka coverage for test files themselves)
                  mkdir ~/artifacts/tests-coverage/
                  cp .coverage ~/artifacts/tests-coverage/

                  # Each test function runs in an isolated Docker container and results in a new .coverage file which we need to combine
                  ls -la ~/artifacts/*/.coverage

                  pip install "coverage==4.5.4" "codecov==2.1.3" "apache-libcloud==2.8.3"
                  cp .circleci/.coveragerc_ci .coveragerc

                  # Generate combined .coverage file for all our test functions
                  ls -la .coverage*
                  coverage combine ~/artifacts/*/.coverage
                  ls -la .coverage*

                  # coverage data from inside docker contains uses different paths which we need to normalize for
                  # coverage combine and codecov reporting and merging to work.
                  sed -i "s#/agent_source/#/home/circleci/scalyr-agent-2/#g" .coverage

                  # Print the report
                  coverage report -i

                  # Submit it to codecov.io
                  coverage xml --rcfile=.coveragerc -i -o coverage.xml

                  ./scripts/submit-codecov-data.sh

                  # Combine it and upload it to S3
                  coverage combine || true
                  export PYTHONPATH=.
                  ./scripts/circleci/upload-coverage-data-to-s3.py ".coverage"

  init-cached-docker-image:
    description: "Base command which initialized Docker image cache."
    parameters:
      cache-key-prefix:
        type: string
      cache-path:
        type: string
      image-builder-path:
        type: string
      python_executable_path:
        type: string
        default: "/usr/bin/env python"
    steps:
      - run:
          name: "Get checksum file for builder '<< parameters.image-builder-path >>'."
          command: |
            python -m << parameters.image-builder-path >> --checksum > ~/image_checksum

      - restore_cache:
          name: "Restore docker image file for the builder '<< parameters.image-builder-path >>'."
          key: << parameters.cache-key-prefix >>-{{ .Branch }}-{{ checksum "~/image_checksum" }}-<< pipeline.parameters.cache_version_docker_images >>

      - run:
          name: "Build image by '<< parameters.image-builder-path >>' builder."
          command: |
             << parameters.python_executable_path >> -m << parameters.image-builder-path >> --build-with-cache << parameters.cache-path >>

      - save_cache:
          name: "Save docker image of the builder '<< parameters.image-builder-path >>' into cache."
          key: << parameters.cache-key-prefix >>-{{ .Branch }}-{{ checksum "~/image_checksum" }}-<< pipeline.parameters.cache_version_docker_images >>
          paths:
            - << parameters.cache-path >>

      - run:
          name: "Remove image checksum file."
          command: |
            rm -f ~/image_checksum

  install-cached-tox:
    description: "Base command which pre-populates cache for a specific tox target without running the tests."
    parameters:
      target_name:
        type: string
        default: ""
    steps:
      - restore_cache:
          name: "Restore Python Dependencies cache"
          key: deps-tox-{{ .Branch }}-3.6-venv-{{ checksum "dev-requirements.txt" }}-<< pipeline.parameters.cache_version_py_dependencies >>

      - run:
          name: Install Dependencies
          shell: bash
          command: |
            pip install "tox==<< pipeline.parameters.default_tox_version >>"

      - save_cache:
          name: "Save Python Dependencies cache"
          key: deps-tox-{{ .Branch }}-3.6-venv-{{ checksum "dev-requirements.txt" }}-<< pipeline.parameters.cache_version_py_dependencies >>
          paths:
            - "~/.cache/pip"

      - when:
          condition: << parameters.target_name >>
          steps:
            - run:
                name: "Init tox environment for target: '<< parameters.target_name >>'"
                command: |
                  tox -e<< parameters.target_name >> --notest

  package-test:
    description: "A base command for package smoke tests. It invokes tox / shell command with name '<parameters.command>'"
    parameters:
      distribution:
        description: "The name of the distribution where the agent will be installed."
        type: string
      python_version:
        description: "The version of the python interpreter to install in distribution."
        type: string
        default: ""
      tox_target:
        description: "Tox target name used to run the tests."
        type: string
      agent_host_name_prefix:
        description: "Host name for the agent instances that will be started during job."
        type: string
        default: ""
      upload_coverage:
        description: "True to combine and upload coverage data to codecov.io."
        type: boolean
        default: false
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: false
          version: 20.10.12

      - install-cached-tox:
          target_name: << parameters.tox_target >>

      - init-cached-docker-image:
          cache-key-prefix: fpm-builder
          cache-path: ~/fpm-builder-cache
          image-builder-path: tests.image_builder.distributions.fpm_package_builder.cmd
          python_executable_path: ./.tox/<< parameters.tox_target >>/bin/python

      - init-cached-docker-image:
          cache-key-prefix: << parameters.distribution >>
          cache-path: ~/<< parameters.distribution >>
          image-builder-path: tests.image_builder.distributions.<< parameters.distribution >>.cmd
          python_executable_path: ./.tox/<< parameters.tox_target >>/bin/python

      - run-tox-target:
          agent_host_name: << parameters.agent_host_name_prefix >>-<< parameters.distribution >>-<< parameters.python_version >>
          target_name:  << parameters.tox_target >>
          upload_coverage: << parameters.upload_coverage >>

      - slack/status:
          fail_only: true
          only_for_branches: master

  monitors-tests:
    description: "A base command for monitors smoke tests."
    parameters:
      distribution:
        description: "The name of the distribution where the agent will be installed."
        type: string
      python_version:
        description: "The version of the python interpreter to install in distribution."
        type: string
        default: ""
      tox_target:
        description: "Tox target name used to run the tests."
        type: string
      agent_host_name_prefix:
        description: "Host name for the agent instances that will be started during job."
        type: string
        default: ""
      upload_coverage:
        description: "True to combine and upload coverage data to codecov.io."
        type: boolean
        default: false
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: false

      - install-cached-tox:
          target_name: << parameters.tox_target >>

      - init-cached-docker-image:
          cache-key-prefix: monitors-builder
          cache-path: ~/monitors-builder-cache
          image-builder-path: tests.image_builder.monitors.base.cmd
          python_executable_path: ./.tox/<< parameters.tox_target >>/bin/python

      - run-tox-target:
          agent_host_name: << parameters.agent_host_name_prefix >>-<< parameters.distribution >>-<< parameters.python_version >>
          target_name:  << parameters.tox_target >>
          upload_coverage: << parameters.upload_coverage >>

      - slack/status:
          fail_only: true
          only_for_branches: master

  ami-tests:
    description: "Run scalyr agent packages sanity tests based on EC2/Libcloud."
    parameters:
      test_type:
        description: "Type of tests to run."
        type: enum
        enum:
          - "development"
          - "stable"
      test_os:
        description: "Tests for which operating system should run."
        type: enum
        enum:
          - "windows"
          - "linux"
        # URL to the installer script to use with the tests. We default to stable version, but
        # you can change that value if you made changes to the installer script and you want
        # to easily test them against all the distrod we run AMI tests on
      installer_script_url:
        description: "URL to the installer script which to use for the install and upgrade tests."
        type: string
        default: "https://www.scalyr.com/scalyr-repo/stable/latest/install-scalyr-agent-2.sh"
    steps:
      - add_ssh_keys:
          fingerprints:
            - "7b:26:91:6b:a0:9d:31:50:4c:8d:31:a3:a6:b8:f2:7a"
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - restore_cache:
          name: "Restore Python Dependencies cache"
          key: deps-<<pipeline.parameters.cache_version_py_dependencies>>-py310-{{ .Branch }}-ami-tests-{{ checksum "tests/ami/requirements.txt" }}
      - run:
          name: Install Python Dependencies
          command: |
            # NOTE: We need to upgrade pip otherwise installation from git fails
            python -m pip install --user --upgrade pip

            # Install dependencies
            python -m pip install --user "requests"
            python -m pip install --user -r tests/ami/requirements.txt
      - save_cache:
          name: "Save Python Dependencies cache"
          key: deps-<<pipeline.parameters.cache_version_py_dependencies>>-py310-{{ .Branch }}-ami-tests-{{ checksum "tests/ami/requirements.txt" }}
          paths:
            - "~/.cache/pip"
      - run:
          # Step which cleans up any old nodes which might have been left running because a
          # previous build was canceled half way through or similar
          name: Clean Up Old Stray EC2 Instances
          environment:
            KEY_NAME: "circleci"
            PRIVATE_KEY_PATH: "~/.ssh/id_rsa_7b26916ba09d31504c8d31a3a6b8f27a"
            PYTHONPATH: "."
          command: |
            export ACCESS_KEY=${AWS_ACCESS_KEY}
            export SECRET_KEY=${AWS_SECRET_KEY}

            ./tests/ami/cleanup_old_test_instances.py
      - run:
          name: "Run package tests on EC2 instances (<< parameters.test_os >>)"
          environment:
            KEY_NAME: "circleci"
            PRIVATE_KEY_PATH: "~/.ssh/id_rsa_7b26916ba09d31504c8d31a3a6b8f27a"
            PYTHONPATH: "."
          no_output_timeout: 25m
          command: |
            export ACCESS_KEY=${AWS_ACCESS_KEY}
            export SECRET_KEY=${AWS_SECRET_KEY}
            export INSTALLER_SCRIPT_URL="<< parameters.installer_script_url >>"

            # If testing type is "development" we use installer script which is built in another job.
            if [ "<< parameters.test_type >>" = "development" ]; then
              export INSTALLER_SCRIPT_URL="/tmp/workspace/installScalyrAgentV2.sh"
            fi

            set +e

            max_attempts="2"
            sleep_delay="15"

            i=0
            until [ "$i" -ge ${max_attempts} ]; do
                echo "Running tests command"

                # On subsequent runs we enable VERBOSE flag to perhaps make
                # troubleshooting easier
                if [ "${i}" -ge 1 ]; then
                    export VERBOSE="true"
                fi

                ./scripts/circleci/run-ami-tests-in-bg.sh << parameters.test_type >> << parameters.test_os >>
                exit_code=$?

                # We preserve logs of all the runs - we move logs to directory per run iteration
                mkdir -p outputs/run_$i/
                cp outputs/*.log outputs/run_$i/
                rm outputs/*.log

                if [ "${exit_code}" -eq 0 ]; then
                    echo "Command exited with 0, breaking from the loop."
                    break
                else
                    echo "Command exited with non-zero status, retrying in ${sleep_delay} seconds..."
                fi
                i=$((i+1))
                sleep ${sleep_delay}
              done

              set -e

              if [ "${exit_code}" -ne 0 ]; then
                  echo "Command failed to exit with zero exit code after 2 attempts, failing (exit_code=${exit_code})"
                  exit 1
              fi

              exit 0

      - store_artifacts:
          path: outputs

      - slack/status:
          fail_only: true
          only_for_branches: master

jobs:
  unittest-310:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.10
    steps:
      - unittest_tox:
          python_version: "3.10"
          tox_target: "py3.10-unit-tests"
  unittest-38:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.8
    steps:
      - unittest_tox:
          python_version: "3.8"
          tox_target: "py3.8-unit-tests"

  unittest-37:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.7
    steps:
      - unittest_tox:
          python_version: "3.7"
          tox_target: "py3.7-unit-tests"

  unittest-36:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - unittest_tox:
          python_version: "3.6"
          tox_target: "py3.6-unit-tests"

  unittest-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5
    steps:
      - unittest_tox:
          python_version: "3.5"
          tox_target: "py3.5-unit-tests"

  unittest-38-osx:
    working_directory: ~/scalyr-agent-2
    macos:
      xcode: "13.2.1"
    environment:
      PYTHON: 3.8.12
      # Updating homebrew is slow so we skip it
      HOMEBREW_NO_AUTO_UPDATE: 1
    steps:
      - checkout
      - run:
          name: Install pyenv
          shell: bash
          command: |
            brew install pyenv
      - restore_cache:
          name: Restore pyenv cache
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-xcode-13.2.1-tox-{{ .Branch }}-py-3.8-osx-venv-{{ checksum "dev-requirements.txt" }}-pyenv
      - run:
          name: Install Python
          command: |
            # For Python < 3.8 we need a workaround so the install doesn't fail
            # CFLAGS="-I$(brew --prefix openssl)/include -I$(brew --prefix bzip2)/include -I$(brew --prefix readline)/include -I$(xcrun --show-sdk-path)/usr/include"
            # LDFLAGS="-L$(brew --prefix openssl)/lib -L$(brew --prefix readline)/lib -L$(brew --prefix zlib)/lib -L$(brew --prefix bzip2)/lib"
            # pyenv install --patch "$PYTHON" < <(curl -sSL https://github.com/python/cpython/commit/8ea6353.patch\?full_index\=1)
            pyenv install "$PYTHON" -s
      - save_cache:
          name: Save pyenv cache
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-xcode-13.2.1-tox-{{ .Branch }}-py-3.8-osx-venv-{{ checksum "dev-requirements.txt" }}-pyenv
          paths:
            - ~/.pyenv
      - restore_cache:
          name: Restore pip cache
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-xcode-13.2.1-tox-{{ .Branch }}-py-3.8-osx-venv-{{ checksum "dev-requirements.txt" }}-pip
      - run:
          name: Install Dependencies
          command: |
            hash -r
            eval "$(pyenv init --path)"
            pyenv local $PYTHON
            python -m pip install virtualenv
            python -m virtualenv venv
            ./venv/bin/pip install --upgrade pip
            ./venv/bin/pip install "tox==<< pipeline.parameters.default_tox_version >>"
      - run:
          name: Run Unit Tests
          command: |
            pyenv local $PYTHON
            source ./venv/bin/activate
            tox -epy3.8-unit-tests
      - save_cache:
          name: Save pip cache
          key: deps-<< pipeline.parameters.cache_version_py_dependencies >>-xcode-13.2.1-tox-{{ .Branch }}-py-3.8-osx-venv-{{ checksum "dev-requirements.txt" }}-pip
          paths:
            - ~/.cache/pip
      - slack/status:
          fail_only: true
          only_for_branches: master

  unittest-310-windows:
    # TODO: That's a temporary in-line definition from slack orb. We can remove it once
    # https://github.com/CircleCI-Public/slack-orb/pull/152 is merged
    parameters:
      webhook:
        type: string
        default: ${SLACK_WEBHOOK}
        description: >
          Enter either your Webhook value or use the CircleCI UI to add your
          token under the 'SLACK_WEBHOOK' env var

      success_message:
        type: string
        default: ":tada: A $CIRCLE_JOB job has succeeded!"
        description: Enter custom message.

      failure_message:
        type: string
        default: ":red_circle: A $CIRCLE_JOB job has failed!"
        description: Enter custom message.

      success_only:
        type: boolean
        default: false
        description: >
          If `true`, notifications of failed jobs will not be sent.

      fail_only:
        type: boolean
        default: true
        description: >
          If `true`, notifications of successful jobs will not be sent.

      mentions:
        type: string
        default: ""
        description: >
          A comma separated list of user IDs. No spaces.

      only_for_branches:
        type: string
        default: "master"
        description: >
          If set, a comma-separated list of branches for which to send
          notifications. No spaces.

      include_project_field:
        type: boolean
        default: true
        description: >
          Whether or not to include the Project field in the message

      include_job_number_field:
        type: boolean
        default: true
        description: >
          Whether or not to include the Job Number field in the message

      include_visit_job_action:
        type: boolean
        default: true
        description: >
          Whether or not to include the Visit Job action in the message

      channel:
        type: string
        default: "#cloud-tech"
        description: >
          ID of channel if set, overrides webhook's default channel setting

      python_version:
        default: 3.10.4
        type: string
        description: "Version of Python interpreter to use."

    working_directory: ~/scalyr-agent-2
    executor:
      name: win/default
      size: medium
      shell: bash
    environment:
      # NOTE: This should be the same version as we use for pre-built Windows binaries
      PYTHON: << parameters.python_version >>
    steps:
      - checkout
      - restore_cache:
          name: Restore Chocolatey Cache
          key: deps-v4-<< pipeline.parameters.cache_version_py_dependencies >>-choco-{{ .Branch }}-<< parameters.python_version >>-windows-{{ checksum "dev-requirements.txt" }}-{{ checksum "agent_build/requirement-files/compression-requirements.txt" }}-{{ checksum "agent_build/requirement-files/testing-requirements.txt" }}
      - run:
          name: Install Python
          command: |
            # Install Python using chocolatey and set custom cache location so we preserve package cache over builds
            mkdir -p ~/choco-cache
            choco config set cacheLocation ~/choco-cache
            choco install python --version "${PYTHON}" --yes --limit-output --no-progress

            # Add Python we installed to PATH and make sure it has precedence over system Python
            echo "export PATH=\"/c/Python310:/c/Python310/Scripts:/c/Users/circleci/AppData/Roaming/Python/Python310/Scripts:$PATH\"" >> $BASH_ENV
      - save_cache:
          name: Save Chocolatey Cache
          key: deps-v4-<< pipeline.parameters.cache_version_py_dependencies >>-choco-{{ .Branch }}-<< parameters.python_version >>-windows-{{ checksum "dev-requirements.txt" }}-{{ checksum "agent_build/requirement-files/compression-requirements.txt" }}-{{ checksum "agent_build/requirement-files/testing-requirements.txt" }}
          paths:
            - ~/choco-cache
            # Actual package files are stored in NuGet cache
            - C:\Users\circleci\AppData\Local\NuGet\Cache
      - restore_cache:
          name: Restore Python Dependencies Cache
          key: deps-v3-<< pipeline.parameters.cache_version_py_dependencies >>-tox-{{ .Branch }}-<< parameters.python_version >>-windows-{{ checksum "dev-requirements.txt" }}-{{ checksum "agent_build/requirement-files/compression-requirements.txt" }}-{{ checksum "agent_build/requirement-files/testing-requirements.txt" }}
      - run:
          name: Install Python Dependencies
          command: |
            python.exe --version
            python.exe -m pip install --user --upgrade "tox==<< pipeline.parameters.default_tox_version >>"
            python.exe -m pip install --user --upgrade "pip==<< pipeline.parameters.default_pip_version >>"
      - run:
          name: Run Unit Tests under Python 3.10
          no_output_timeout: 8m
          command: |
            # NOTE: If we don't redirect the output, Windows this step doesn't correctly exit even
            # after the tox commands finishes. That's why we use the redirect workaround. Sadly
            # this means we don't see output immediately as it produced (using redirect + tee also
            # results in the job not exiting when tox command finishes).
            tox.exe -epy3.10-windows-unit-tests > output 2>&1
            EXIT_CODE=$?
            cat output

            if [ "${EXIT_CODE}" -ne 0 ]; then
              exit ${EXIT_CODE}
            fi

            tox.exe -epy3.10-windows-unit-tests-windows-platform > output 2>&1
            EXIT_CODE=$?
            cat output

            exit ${EXIT_CODE}
      - save_cache:
          name: Save Python Dependencies Cache
          key: deps-v3-<< pipeline.parameters.cache_version_py_dependencies >>-tox-{{ .Branch }}-<< parameters.python_version >>-windows-{{ checksum "dev-requirements.txt" }}-{{ checksum "agent_build/requirement-files/compression-requirements.txt" }}-{{ checksum "agent_build/requirement-files/testing-requirements.txt" }}
          paths:
            - C:\Users\circleci\AppData\Local\pip\Cache
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test-results
      - run:
          name: Submit Coverage Data to codecov.io and Combine it and Upload it to S3
          command: |
            ls -la .coverage* || true

            python.exe -m pip install "coverage==4.5.4" "codecov==2.1.3" "apache-libcloud==2.8.3"
            cp .circleci/.coveragerc_ci .coveragerc

            # Print the report
            coverage.exe report -i

            # Submit it to codecov.io
            coverage.exe xml --rcfile=.coveragerc -i -o coverage.xml
            ./scripts/submit-codecov-data.sh

            # Combine it and upload it to S3
            coverage combine || true
            export PYTHONPATH=.
            ./scripts/circleci/upload-coverage-data-to-s3.py ".coverage"

      # TODO: That's a temporary in-line definition from slack orb. We can remove it once
      # https://github.com/CircleCI-Public/slack-orb/pull/152 is merged
      - run:
          name: Provide error if curl is not installed.
          command: |
            which curl > curl_exists; echo $? | grep -q '1' && echo curl not installed && rm curl_exists && exit 1
            rm curl_exists

      - run:
          name: Slack - Setting Failure Condition
          command: |
            echo 'export SLACK_BUILD_STATUS="fail"' >> $BASH_ENV
          when: on_fail

      - run:
          name: Slack - Setting Success Condition
          command: |
            echo 'export SLACK_BUILD_STATUS="success"' >> $BASH_ENV
          when: on_success

      - run:
          name: Provide error if non-bash shell
          command: |
            if [ ! -x /bin/bash ]; then
              echo Bash not installed.
              exit 1
            fi

      - run:
          name: Slack - Sending Status Alert
          shell: bash
          when: always
          command: |
            current_branch_in_filter=false

            IFS="," read -ra BRANCH_FILTERS \<<< "<< parameters.only_for_branches >>"

            for i in "${BRANCH_FILTERS[@]}"; do
              if [ "${i}" == "${CIRCLE_BRANCH}" ]; then
                current_branch_in_filter=true
              fi
            done

            if [ "x" == "x<< parameters.only_for_branches>>" ] || [ "$current_branch_in_filter" = true ]; then
              # Provide error if no webhook is set and error. Otherwise continue
              if [ -z "<< parameters.webhook >>" ]; then
                echo "NO SLACK WEBHOOK SET"
                echo "Please input your SLACK_WEBHOOK value either in the settings for this project, or as a parameter for this orb."
                exit 1
              else
                #Create Members string
                if [ -n "<< parameters.mentions >>" ]; then
                  IFS="," read -ra SLACK_MEMBERS \<<< "<< parameters.mentions >>"
                  for i in "${SLACK_MEMBERS[@]}"; do
                    if [ $(echo ${i} | head -c 1) == "S" ]; then
                      SLACK_MENTIONS="${SLACK_MENTIONS}<!subteam^${i}> "
                    elif echo ${i} | grep -E "^(here|channel|everyone)$" > /dev/null; then
                      SLACK_MENTIONS="${SLACK_MENTIONS}<!${i}> "
                    else
                      SLACK_MENTIONS="${SLACK_MENTIONS}<@${i}> "
                    fi
                  done
                fi
                #If successful
                if [ "$SLACK_BUILD_STATUS" = "success" ]; then
                  #Skip if fail_only
                  if [ << parameters.fail_only >> = true ]; then
                    echo "The job completed successfully"
                    echo '"fail_only" is set to "true". No Slack notification sent.'
                  else
                    curl -X POST -H 'Content-type: application/json' \
                      --data "{ \
                                <<# parameters.channel >>
                                \"channel\": \"<< parameters.channel >>\", \
                                <</ parameters.channel >>
                                \"attachments\": [ \
                                  { \
                                    \"fallback\": \"<< parameters.success_message >>\", \
                                    \"text\": \"<< parameters.success_message >> $SLACK_MENTIONS\", \
                                    \"fields\": [ \
                                      <<# parameters.include_project_field >>
                                      { \
                                        \"title\": \"Project\", \
                                        \"value\": \"$CIRCLE_PROJECT_REPONAME\", \
                                        \"short\": true \
                                      }, \
                                      <</ parameters.include_project_field >>
                                      <<# parameters.include_job_number_field >>
                                      { \
                                        \"title\": \"Job Number\", \
                                        \"value\": \"$CIRCLE_BUILD_NUM\", \
                                        \"short\": true \
                                      } \
                                      <</ parameters.include_job_number_field >>
                                    ], \
                                    \"actions\": [ \
                                      <<# parameters.include_visit_job_action >>
                                      { \
                                        \"type\": \"button\", \
                                        \"text\": \"Visit Job\", \
                                        \"url\": \"$CIRCLE_BUILD_URL\" \
                                      } \
                                      <</ parameters.include_visit_job_action >>
                                    ], \
                                    \"color\": \"#1CBF43\" \
                                  } \
                                ] \
                              } " << parameters.webhook >>
                    echo "Job completed successfully. Alert sent."
                  fi
                else
                  #If Failed

                  #Skip if success_only
                  if [ << parameters.success_only >> = true ]; then
                    echo "The job failed"
                    echo '"success_only" is set to "true". No Slack notification sent.'
                  else
                    curl -X POST -H 'Content-type: application/json' \
                      --data "{ \
                        <<# parameters.channel >>
                        \"channel\": \"<< parameters.channel >>\", \
                        <</ parameters.channel >>
                        \"attachments\": [ \
                          { \
                            \"fallback\": \"<< parameters.failure_message >>\", \
                            \"text\": \"<< parameters.failure_message >> $SLACK_MENTIONS\", \
                            \"fields\": [ \
                              <<# parameters.include_project_field >>
                              { \
                                \"title\": \"Project\", \
                                \"value\": \"$CIRCLE_PROJECT_REPONAME\", \
                                \"short\": true \
                              }, \
                              <</ parameters.include_project_field >>
                              <<# parameters.include_job_number_field >>
                              { \
                                \"title\": \"Job Number\", \
                                \"value\": \"$CIRCLE_BUILD_NUM\", \
                                \"short\": true \
                              } \
                              <</ parameters.include_job_number_field >>
                            ], \
                            \"actions\": [ \
                              <<# parameters.include_visit_job_action >>
                              { \
                                \"type\": \"button\", \
                                \"text\": \"Visit Job\", \
                                \"url\": \"$CIRCLE_BUILD_URL\" \
                              } \
                              <</ parameters.include_visit_job_action >>
                            ], \
                            \"color\": \"#ed5c5c\" \
                          } \
                        ] \
                      } " << parameters.webhook >>
                    echo "Job failed. Alert sent."
                  fi
                fi
              fi
            else
              echo "Current branch is not included in only_for_branches filter; no status alert will be sent"
            fi

  unittest-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7
    steps:
      - unittest_tox:
          python_version: "2.7"
          tox_target: "coverage"
          upload_coverage: true

  smoke-standalone-27-tls12:
    docker:
      - image: cimg/python:2.7
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: false
      - run:
          command: |
            docker container create --name dummy -v shared_vol:/app alpine && \
            docker cp $(pwd)/.circleci/smoketest_standalone.sh dummy:/app/ && \
            docker run -it -v shared_vol:/app -e TEST_BRANCH=${CIRCLE_BRANCH} -e MAX_WAIT=150 -e PYTHON_VERSION=2.7.nossl -e SCALYR_API_KEY=${SCALYR_API_KEY} -e READ_API_KEY=${READ_API_KEY} -e SCALYR_SERVER=${SCALYR_SERVER} -e CIRCLE_BUILD_NUM=${CIRCLE_BUILD_NUM} scalyr/scalyr-agent-ci-unittest:4 /app/smoketest_standalone.sh && \
            docker rm dummy;

      - slack/status:
          fail_only: true
          only_for_branches: master

  smoke-docker-json:
    working_directory: ~/scalyr-agent-2
    machine:
      image: ubuntu-2004:202111-02
    steps:
      - checkout
      - restore_cache:
          key: deps2-{{ .Branch }}-docker-json-{{ checksum "dev-requirements.txt" }}-v2
      - run:
          name: "Install Python Dependencies"
          command: |
            python3 --version
            python3 -m venv venv
            source venv/bin/activate
            pip install -r dev-requirements.txt
            pip install "apache-libcloud==3.4.1"
      - save_cache:
          name: "Save Dependencies Cache"
          key: deps2-{{ .Branch }}-docker-json-{{ checksum "dev-requirements.txt" }}-v2
          paths:
            - "venv"
            - "~/.cache/pip"
      - run:
          name: Run Tests (with coverage)
          command: |
            source ./.circleci/smoketest_docker.sh scalyr/scalyr-agent-ci-unittest:4 docker-json 150
      - run:
          name: Submit Coverage Data to codecov.io and Combine it and Upload it to S3
          command: |
            ls -la .coverage* || true

            cp .circleci/.coveragerc_ci .coveragerc

            source venv/bin/activate

            # Ensure consistent paths for all the code coverage reports
            sed -i "s#/usr/share/scalyr-agent-2/py/#/home/circleci/scalyr-agent-2/#g" .coverage

            # Submit it to codecov.io
            ./venv/bin/coverage xml --rcfile=.coveragerc -i -o coverage.xml
            ./scripts/submit-codecov-data.sh

            # Combine it and upload it to S3
            ./venv/bin/coverage combine || true
            export PYTHONPATH=.
            ./scripts/circleci/upload-coverage-data-to-s3.py ".coverage"

      - slack/status:
          fail_only: true
          only_for_branches: master

  smoke-docker-api-raw-logs-disabled:
    working_directory: ~/scalyr-agent-2
    machine:
      image: ubuntu-2004:202111-02
    steps:
      - checkout
      - restore_cache:
          key: deps2-{{ .Branch }}-docker-api-{{ checksum "dev-requirements.txt" }}-v1
      - run:
          name: "Install Python Dependencies"
          command: |
            python3 --version
            python3 -m venv venv
            source venv/bin/activate
            pip install -r dev-requirements.txt
            pip install "apache-libcloud==3.4.1"
      - save_cache:
          name: "Save Dependencies Cache"
          key: deps2-{{ .Branch }}-docker-api-{{ checksum "dev-requirements.txt" }}-v1
          paths:
            - "venv"
            - "~/.cache/pip"
      - run:
          name: Run Tests (with coverage)
          command: |
            source ./.circleci/smoketest_docker.sh scalyr/scalyr-agent-ci-unittest:4 docker-api 200
      - run:
          name: Submit Coverage Data to codecov.io and Combine it and Upload it to S3
          command: |
            ls -la .coverage* || true

            cp .circleci/.coveragerc_ci .coveragerc

            source venv/bin/activate

            # Ensure consistent paths for all the code coverage reports
            sed -i "s#/usr/share/scalyr-agent-2/py/#/home/circleci/scalyr-agent-2/#g" .coverage

            # Submit it to codecov.io
            ./venv/bin/coverage xml --rcfile=.coveragerc -i -o coverage.xml
            ./scripts/submit-codecov-data.sh

            # Combine it and upload it to S3
            ./venv/bin/coverage combine || true
            export PYTHONPATH=.
            ./scripts/circleci/upload-coverage-data-to-s3.py ".coverage"

      - slack/status:
          fail_only: true
          only_for_branches: master

  smoke-docker-syslog:
    working_directory: ~/scalyr-agent-2
    machine:
      image: ubuntu-2004:202111-02
    steps:
      - checkout
      - restore_cache:
          key: deps2-{{ .Branch }}-docker-json-{{ checksum "dev-requirements.txt" }}-v2
      - run:
          name: "Install Python Dependencies"
          command: |
            python3 --version
            python3 -m venv venv
            source venv/bin/activate
            pip install -r dev-requirements.txt
            pip install "apache-libcloud==3.4.1"
      - save_cache:
          name: "Save Dependencies Cache"
          key: deps2-{{ .Branch }}-docker-json-{{ checksum "dev-requirements.txt" }}-v2
          paths:
            - "venv"
            - "~/.cache/pip"
      - run:
          name: Run Tests (with coverage)
          command: |
            source ./.circleci/smoketest_docker.sh scalyr/scalyr-agent-ci-unittest:4 docker-syslog 150
      - run:
          name: Submit Coverage Data to codecov.io and Combine it and Upload it to S3
          command: |
            ls -la .coverage* || true

            cp .circleci/.coveragerc_ci .coveragerc

            source venv/bin/activate

            # Ensure consistent paths for all the code coverage reports
            sed -i "s#/usr/share/scalyr-agent-2/py/#/home/circleci/scalyr-agent-2/#g" .coverage

            # Submit it to codecov.io
            ./venv/bin/coverage xml --rcfile=.coveragerc -i -o coverage.xml
            ./scripts/submit-codecov-data.sh

            # Combine it and upload it to S3
            ./venv/bin/coverage combine || true
            export PYTHONPATH=.
            ./scripts/circleci/upload-coverage-data-to-s3.py ".coverage"

      - slack/status:
          fail_only: true
          only_for_branches: master

  smoke-k8s:
    working_directory: ~/scalyr-agent-2
    machine:
      image: ubuntu-2004:202111-02
    environment:
      K8S_VERSION: v1.18.0
      KUBECONFIG: /home/circleci/.kube/config
      MINIKUBE_VERSION: v1.24.0
      MINIKUBE_WANTUPDATENOTIFICATION: false
      MINIKUBE_WANTREPORTERRORPROMPT: false
      MINIKUBE_HOME: /home/circleci
      CHANGE_MINIKUBE_NONE_USER: true
    steps:
      - checkout
      - restore_cache:
          key: deps2-{{ .Branch }}-smoke-k8s-{{ checksum "dev-requirements.txt" }}
      - run:
          name: "Install Python Dependencies"
          command: |
            python3 --version
            python3 -m venv venv
            source venv/bin/activate
            pip install -r dev-requirements.txt
            pip install "apache-libcloud==3.4.1"
      - save_cache:
          name: "Save Dependencies Cache"
          key: deps2-{{ .Branch }}-smoke-k8s-{{ checksum "dev-requirements.txt" }}
          paths:
            - "venv"
            - "~/.cache/pip"
      - run:
          name: setup kubectl
          command: |
            curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/${K8S_VERSION}/bin/linux/amd64/kubectl && chmod +x kubectl && sudo mv kubectl /usr/local/bin/
            mkdir -p ${HOME}/.kube
            touch ${HOME}/.kube/config
      - run:
          name: install k8s dependencies
          command: |
            sudo apt-get update
            sudo apt-get install -y conntrack
      - run:
          name: setup minikube
          command: |
            curl -Lo minikube https://github.com/kubernetes/minikube/releases/download/${MINIKUBE_VERSION}/minikube-linux-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/
      - run:
          name: start minikube
          command: |
            sudo -E minikube start --vm-driver=none --cpus 2 --memory 2048 --kubernetes-version=${K8S_VERSION}
      - run:
          name: wait for minikube
          command: |
            JSONPATH='{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}';
            until kubectl get nodes -o jsonpath="$JSONPATH" 2>&1 | grep -q "Ready=True"; do
              sleep 1;
            done
      - run:
          name: fix RBAC
          command: |
            # make default account cluster-admin
            kubectl create clusterrolebinding add-on-cluster-admin --clusterrole cluster-admin --serviceaccount=kube-system:default
      - run:
          name: dump cluster-info
          command: |
            kubectl cluster-info
            kubectl get po --all-namespaces
      - run:
          name: Run Tests (with coverage)
          command: |
            source ./.circleci/smoketest_k8s.sh scalyr/scalyr-agent-ci-unittest:4 150 no_delete_existing_k8s_objs
      - run:
          name: Submit Coverage Data to codecov.io and Combine it and Upload it to S3
          command: |
            ls -la .coverage* || true

            cp .circleci/.coveragerc_ci .coveragerc

            source venv/bin/activate

            # Ensure consistent paths for all the code coverage reports
            sed -i "s#/usr/share/scalyr-agent-2/py/#/home/circleci/scalyr-agent-2/#g" .coverage

            # Submit it to codecov.io
            ./venv/bin/coverage xml --rcfile=.coveragerc -i -o coverage.xml
            ./scripts/submit-codecov-data.sh

            # Combine it and upload it to S3
            ./venv/bin/coverage combine || true
            export PYTHONPATH=.
            python3 ./scripts/circleci/upload-coverage-data-to-s3.py ".coverage"

      - slack/status:
          fail_only: true
          only_for_branches: master

  lint-checks:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - checkout
      - restore_cache:
          key: deps2-tox-{{ .Branch }}-lint-venv-{{ checksum "dev-requirements.txt" }}-{{ checksum "lint-requirements.txt" }}
      - run:
          name: Install Dependencies
          command: |
            # NOTE: We use precompiled binary since debian sid which contains shellcheck 0.7.0 which we depend on
            # currently (March 25, 2020) contains broken libc version
            sudo wget https://github.com/koalaman/shellcheck/releases/download/stable/shellcheck-stable.linux.x86_64.tar.xz
            sudo tar xvf shellcheck-stable.linux.x86_64.tar.xz
            sudo cp shellcheck-stable/shellcheck /usr/local/bin
            sudo rm -rf shellcheck-stable*
      - run:
          name: Install Python dependencies
          command: |
            pip install "tox==<< pipeline.parameters.default_tox_version >>"
            pip install requests
      - run:
          name: Run Python Lint Checks
          command: |
            export PYTHONPATH=.

            # Small safety check to make sure the build fails if codecov.yml file is invalid.
            # By default codecov doesn't fail on invalid config and simply falls back to
            # system wide default config in case repo local config is invalid. This usually results
            # in confused and undesired behavior.
            ./scripts/circleci/verify-codecov-config.sh

            # Runs script which verifies /addEvents API returns correct response headers. In ideal
            # world, this script would live somewhere else (perhaps as part of monitoring tooling,
            # but for now it will live here.
            ./scripts/verify-add-events-api-response-headers.py

            # Run tox ling target
            tox -e lint
      - run:
          name: Run Shell Scripts Lint Checks
          environment:
            IGNORE_BINARY_DOESNT_EXIST: "0"
          command: |
            ./scripts/shell-scripts-lint.sh
      - run:
          name: Generate Monitor Docs
          command: |
            tox -e generate-monitor-docs
            # Verify there are no changes after generating the docs. If there
            # are, this indicates developer didn't run this target locally and
            # that some files are not up to date
            git status
            git status -- *docs/monitors/*.md */docs/monitorsDmd | (grep -q "nothing to commit" || (echo "Auto-generate monitor doc files are not up to date. Make sure you run tox -e generate-monitor-docs and commit any changed files." && exit 1))
      - save_cache:
          key: deps2-tox-{{ .Branch }}-lint-venv-{{ checksum "dev-requirements.txt" }}-{{ checksum "lint-requirements.txt" }}
          paths:
            - "~/.cache/pip"
      - slack/status:
          fail_only: true
          only_for_branches: master

  sonarcloud-scan:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    environment:
      VERSION: "4.6.0.2311"
      SCANNER_DIRECTORY: "/tmp/cache/scanner"
      SONAR_USER_HOME: "/tmp/cache/scanner/.sonar"
      OS: "linux"
    steps:
      - checkout
      # NOTE: Those steps are based on sonarcloud orb. We can't use the orb
      # directly since it doesn't allow us to specify us a custom path to the
      # config
      - run:
          name: Create cache directory if it doesn't exist
          command: mkdir -p /tmp/cache/scanner
      - restore_cache:
          key: v2-sonarcloud-scanner-4.6.0.2311
      - run:
          name: Download Sonar Scanner
          command: |
            set -e

            if [[ ! -x "$SCANNER_DIRECTORY/sonar-scanner-$VERSION-$OS/bin/sonar-scanner" ]]; then
              curl -Ol https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-$VERSION-$OS.zip
              unzip -qq -o sonar-scanner-cli-$VERSION-$OS.zip -d $SCANNER_DIRECTORY
            fi

            chmod +x $SCANNER_DIRECTORY/sonar-scanner-$VERSION-$OS/bin/sonar-scanner
            chmod +x $SCANNER_DIRECTORY/sonar-scanner-$VERSION-$OS/jre/bin/java
      - save_cache:
          key: v2sonarcloud-scanner-4.6.0.2311
          paths:
            - /tmp/cache/scanner
      - run:
          # NOTE: Sadly there isn't a better way for us to achieve that. We generate coverage
          # data as part of multiple independent workflow jobs so we uploaded
          # coverage data generated by each job to S3 and then pull it down
          # here, combine it and pass it to sonar binary.
          # Since we use multiple independent workflows which run in parallel
          # it also means we can't easily utiize Circle CI artifacts since
          # current Circle CI API doesn't expose an easy way to retrieve
          # artifacts for all the workflows which are part of a particular
          # build.
          name: Download Coverage Data files
          command: |
            pip install "coverage==4.5.4" "apache-libcloud==3.1.0"
            cp .circleci/.coveragerc_ci .coveragerc

            # Download Coverage Data
            export PYTHONPATH=.
            ./scripts/circleci/download-coverage-data-from-s3.py "."
            ls -la .coverage*

            mkdir coverage
            cp .coverage* coverage/

            # Ensure consistent paths for all the code coverage reports
            # NOTE: In seed we need 3 \ for one \
            sed -i "s#C:\\\\\\\Users\\\\\\\circleci\\\\\\\scalyr-agent-2#/home/circleci/scalyr-agent-2#g" .coverage*
            # Replace two \\ with one /
            sed -i "s#\\\\\\\#/#g" .coverage*

            # Combine it
            coverage combine

            cp .coverage coverage/.coverage-combined-final

            # Generate XML file which can be processed by sonarcloud
            coverage xml --rcfile=.coveragerc -i -o coverage.xml

            # Print it
            coverage report

      # Stored all the downloaded coverage files for ease of troubleshooting
      - store_artifacts:
          path: coverage

      - run:
          name: Run Sonar Scanner
          command:
            ${SCANNER_DIRECTORY}/sonar-scanner-${VERSION}-${OS}/bin/sonar-scanner -Dproject.settings=.sonarcloud.properties

  benchmarks-idle-agent-py-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7.17
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 2.7.17 - idle conf 1"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_no_monitored_logs.json"
          agent_server_host: "ci-codespeed-benchmarks-py27-idle-conf-1"
          capture_line_counts: true
          cache_key_name: "benchmarks-idle-27"

  benchmarks-idle-agent-py-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5.9
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 3.5.9 - idle conf 1"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_no_monitored_logs.json"
          agent_server_host: "ci-codespeed-benchmarks-py35-idle-conf-1"
          capture_line_counts: true
          cache_key_name: "benchmarks-idle-35"

  benchmarks-idle-agent-no-monitors-py-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7.17
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 2.7.17 - idle conf 2"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_no_monitored_logs_no_monitors.json"
          agent_server_host: "ci-codespeed-benchmarks-py27-idle-conf-2"
          capture_line_counts: true
          cache_key_name: "benchmarks-idle-agent-no-monitors-py-27"

  benchmarks-idle-agent-no-monitors-py-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5.9
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 3.5.9 - idle conf 2"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_no_monitored_logs_no_monitors.json"
          agent_server_host: "ci-codespeed-benchmarks-py35-idle-conf-2"
          capture_line_counts: true
          cache_key_name: "benchmarks-idle-agent-no-monitors-py-35"

  benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7.17
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 2.7.17 - loaded conf 1"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_single_50mb_access_log_file.json"
          agent_pre_run_command: "wget --directory-prefix=/tmp https://github.com/scalyr/codespeed-agent-fixtures/raw/master/fixtures/logs/access_log_50_mb.log"
          agent_server_host: "ci-codespeed-benchmarks-py27-loaded-conf-1"
          run_time: 140
          capture_agent_status_metrics: true
          capture_line_counts: true
          cache_key_name: "benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-27"

  benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5.9
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 3.5.9 - loaded conf 1"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_single_50mb_access_log_file.json"
          agent_pre_run_command: "wget --directory-prefix=/tmp https://github.com/scalyr/codespeed-agent-fixtures/raw/master/fixtures/logs/access_log_50_mb.log"
          agent_server_host: "ci-codespeed-benchmarks-py35-loaded-conf-1"
          run_time: 140
          capture_line_counts: true
          cache_key_name: "benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-35"

  # NOTE: For the benchmarks below to work correctly "/tmp/random.log" file
  # which is being written to during the benchmark must existing before the
  # agent process is started.
  benchmarks-loaded-agent-single-growing-log-file-20mb-py-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7.17
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 2.7.17 - loaded conf 2"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_single_growing_log_file_with_shell_and_url_monitor.json"
          run_time: 140
          agent_pre_run_command: "touch /tmp/random.log"
          agent_post_run_command: "benchmarks/scripts/write-random-lines.sh /tmp/random.log 2M 10 100 1"
          agent_server_host: "ci-codespeed-benchmarks-py27-loaded-conf-2"
          capture_line_counts: true
          cache_key_name: "benchmarks-loaded-agent-growing-log-file-py-27"

  benchmarks-loaded-agent-single-growing-log-file-20mb-py-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5.9
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 3.5.9 - loaded conf 2"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_single_growing_log_file_with_shell_and_url_monitor.json"
          run_time: 140
          agent_pre_run_command: "touch /tmp/random.log"
          agent_post_run_command: "benchmarks/scripts/write-random-lines.sh /tmp/random.log 2M 10 100 1"
          agent_server_host: "ci-codespeed-benchmarks-py35-loaded-conf-2"
          capture_line_counts: true
          cache_key_name: "benchmarks-loaded-agent-growing-log-file-py-35"

  benchmarks-loaded-agent-single-growing-log-file-180mb-py-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7.17
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 2.7.17 - loaded conf 3"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_single_growing_log_file.json"
          # NOTE: We set agent run time slightly longer than the insert script time run so we give a chance for memory and
          # other metrics to stabilize.
          run_time: 390
          agent_pre_run_command: "touch /tmp/random.log"
          # NOTE: We write a chunk every 1 seconds for a total of 6 minutes.
          # Each chunk is 0.5 MB in size which means we write a total of 360 * 1
          # / 0.5 MB of data
          agent_post_run_command: "benchmarks/scripts/write-random-lines.sh /tmp/random.log 500K 360 100 1 &> /tmp/write_lines_script.log &"
          agent_server_host: "ci-codespeed-benchmarks-py27-loaded-conf-3"
          capture_line_counts: true
          cache_key_name: "benchmarks-loaded-agent-growing-log-file-180-py-27"

  benchmarks-loaded-agent_2-growing_logs-monitors-multiprocess-2-worker-20mb-py-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5.9
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 3.5.9 - loaded conf 4"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_2-growing_logs-monitors-multiprocess-2-worker.json"
          run_time: 140
          agent_pre_run_command: "touch /tmp/random.log & touch /tmp/random2.log"
          agent_post_run_command: "benchmarks/scripts/write-random-lines.sh /tmp/random.log 2M 10 100 1 & benchmarks/scripts/write-random-lines.sh /tmp/random2.log 2M 10 100 1 &"
          agent_server_host: "ci-codespeed-benchmarks-py35-loaded-conf-4"
          capture_line_counts: true
          cache_key_name: "agent_2-growing_logs-monitors-multiprocess-2-worker-py-35"

  benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7.17
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 2.7.17 - loaded conf 5"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_single_50mb_genlog_500k_line_file.json"
          agent_pre_run_command: "wget --directory-prefix=/tmp https://github.com/scalyr/codespeed-agent-fixtures/raw/master/fixtures/logs/scalyr_genlog_500k_line_50_mb.log"
          agent_server_host: "ci-codespeed-benchmarks-py27-loaded-conf-5"
          run_time: 140
          capture_agent_status_metrics: true
          capture_line_counts: true
          cache_key_name: "benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-27"

  benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5.9
    steps:
      - codespeed_agent_process_benchmark:
          codespeed_executable: "Python 3.5.9 - loaded conf 5"
          codespeed_environment: "Circle CI Docker Executor Medium Size"
          agent_config: "benchmarks/configs/agent_single_50mb_genlog_500k_line_file.json"
          agent_pre_run_command: "wget --directory-prefix=/tmp https://github.com/scalyr/codespeed-agent-fixtures/raw/master/fixtures/logs/scalyr_genlog_500k_line_50_mb.log"
          agent_server_host: "ci-codespeed-benchmarks-py35-loaded-conf-5"
          run_time: 140
          capture_agent_status_metrics: true
          capture_line_counts: true
          cache_key_name: "benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-27"

  benchmarks-micro-py-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5.9
    # NOTE: We use larger resource class to speed up the tests. This job only runs on master merge
    # aka not often.
    resource_class: large
    steps:
      - codespeed_micro_benchmarks:
          codespeed_executable: "Python 3.5.9"
          codespeed_environment: "Circle CI Docker Executor Large Size"
          cache_key_name: "benchmarks-micro-py36"

  benchmarks-micro-py-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7.17
    # NOTE: We use larger resource class to speed up the tests. This job only runs on master merge
    # aka not often.
    resource_class: large
    steps:
      - codespeed_micro_benchmarks:
          codespeed_executable: "Python 2.7.17"
          codespeed_environment: "Circle CI Docker Executor Large Size"
          cache_key_name: "benchmarks-micro-py27"

  # Job which sends notification to Slack after benchmark run has completed
  # on master merge / push.
  send-benchmark-results-and-graphs-to-slack:
    working_directory: ~/scalyr-agent-2
    circleci_ip_ranges: true # opt into this functionlity for whitelisting purposes. Needed some Slack blocks
                             # some EC2 IP ranges
    docker:
      - image: cimg/python:3.5.9
    steps:
      - checkout
      - run:
          name: Set Permissions
          command: |
            # Set permissions so we can directly restore into /usr/local/bin
            sudo chmod 777 /usr/local/bin
      - restore_cache:
          key: deps2-tox-{{ .Branch }}-3.5-capture-screenshot
      - run:
          name: Download and install Phantom JS
          command: |
            if [ ! -e "/usr/local/bin/phantomjs" ]; then
              echo "Downloading and installing PhantomJS"
              wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2
              tar -xf phantomjs-2.1.1-linux-x86_64.tar.bz2
              sudo cp phantomjs-2.1.1-linux-x86_64/bin/phantomjs /usr/local/bin
            fi
      - save_cache:
          name: Save PhantomJS Cache
          key: deps2-tox-{{ .Branch }}-3.5-capture-screenshot
          paths:
            - /usr/local/bin/phantomjs
      - run:
          name: Capture CodeSpeed Graphs Screenshots and Post Notification to Slack
          environment:
            SLACK_CHANNEL: "#cloud-tech"
          command: |
            export OPENSSL_CONF=/etc/ssl/
            mkdir -p /tmp/codespeed-screenshots/

            # Capture the graph screenshots
            phantomjs scripts/phantomjs/capture_codespeed_graphs_screenshots.js

            # Send notication to Slack
            export PYTHONPATH=.
            ./scripts/send-benchmark-completion-notification-to-slack.py /tmp/codespeed-screenshots/

  smoke-standalone-35-rate-limit:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5
    steps:
      - smoke-standalone-tox:
          python_version: "3.5"
          tox_target: "py3.5-smoke-tests-rate-limit"

  smoke-standalone-38:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.8
    steps:
      - smoke-standalone-tox:
          python_version: "3.8"
          tox_target: "py3.8-smoke-tests"

  smoke-standalone-37:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.7
    steps:
      - smoke-standalone-tox:
          python_version: "3.7"
          tox_target: "py3.7-smoke-tests"

  smoke-standalone-36:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - smoke-standalone-tox:
          python_version: "3.6"
          tox_target: "py3.6-smoke-tests"

  smoke-standalone-35:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.5
    steps:
      - smoke-standalone-tox:
          python_version: "3.5"
          tox_target: "py3.5-smoke-tests"

  smoke-standalone-27:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:2.7
    steps:
      - smoke-standalone-tox:
          python_version: "2.7"
          tox_target: "py2.7-smoke-tests"

  package-test-rpm:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "amazonlinux2"
          agent_host_name_prefix: "package-test"
          tox_target: agent_distributions_tests_amazonlinux2

  package-test-deb:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "ubuntu2204"
          agent_host_name_prefix: "package-test"
          tox_target: agent_distributions_tests_ubuntu2204

  # Circle CI jobs which build agent packages for each PR.
  package-build-deb:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "ubuntu1804"
          agent_host_name_prefix: "-test"
          tox_target: agent_deb_package

  package-build-rpm:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "centos8"
          agent_host_name_prefix: "-test"
          tox_target: agent_rpm_package

  smoke-monitors-tests:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - monitors-tests:
          distribution: "ubuntu1804"
          python_version: "python3"
          agent_host_name_prefix: "monitors-test"
          tox_target: agent_monitors_ubuntu
          upload_coverage: true

  smoke-rpm-package-py3:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "amazonlinux2"
          python_version: "python3"
          agent_host_name_prefix: "smoke"
          tox_target: agent_package_smoke_test_amazonlinux_python3

  smoke-rpm-package-py2:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "amazonlinux2"
          python_version: "python2"
          tox_target: agent_package_smoke_test_amazonlinux_python2

  smoke-deb-package-py3:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "ubuntu1804"
          python_version: "python3"
          tox_target: agent_package_smoke_test_ubuntu_python3

  smoke-deb-package-py2:
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - package-test:
          distribution: "ubuntu1804"
          python_version: "python2"
          tox_target: agent_package_smoke_test_ubuntu_python2

  send-circle-ci-usage-report:
    description: "Job which emails weekly Circle CI usage report"
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.6
    steps:
      - checkout
      - run:
          name: Email Usage Report
          command: |
            export PYTHONPATH=.
            python scripts/circleci_usage_data.py --project_slug=gh/scalyr/scalyr-agent-2 \
                --workflows=unit-tests,smoke-tests,package-tests,benchmarks --status=success \
                --branch=all --branch-limit=5 --limit=2 \
                --email=cloudtech-builds@scalyr.com

  build-windows-package:
    description: "Build windows MSI installer."
    executor:
      name: win/default
      size: "medium"
      # windows-server-2019-vs2019:previous
      version: "previous"
      shell: bash
    parameters:
      python-version:
        description: Version of the Python interpreter to use.
        default: 3.10.4
        type: string
    steps:
      - checkout
      - restore_cache:
          name: Restore Python installer Cache
          key: windows-v2-python-installer-cache-{{ .Branch }}-<< parameters.python-version >>

      - restore_cache:
          name: Restore Wix cache
          key: windows-wix-cache-{{ .Branch }}

      - run:
          name: Extract Wix.
          shell: powershell.exe
          command: |
            $ProgressPreference = "SilentlyContinue"
            mkdir wix311_binaries -Force
            if (!(Test-Path .\wix311_binaries\wix311-binaries.zip -PathType Leaf)) {
              wget https://github.com/wixtoolset/wix3/releases/download/wix3112rtm/wix311-binaries.zip -OutFile wix311_binaries\wix311-binaries.zip
            }
            Expand-Archive -LiteralPath wix311_binaries\wix311-binaries.zip -DestinationPath C:\wix311

      - run:
          name: Install python.
          shell: powershell.exe
          command: |
            $ProgressPreference = "SilentlyContinue"
            mkdir python_installer -Force
            if (!(Test-Path .\python_installer\python-amd64.exe -PathType Leaf)) {
                wget -O .\python_installer\python-amd64.exe https://www.python.org/ftp/python/<< parameters.python-version >>/python-<< parameters.python-version >>-amd64.exe
            }
            python_installer\python-amd64.exe /quiet /passive

      - save_cache:
          name: Save Wix Cache
          key: windows-wix-cache-{{ .Branch }}
          paths:
            - "wix311_binaries"

      - save_cache:
          name: Save Python Installer Cache
          key: windows-v2-python-installer-cache-{{ .Branch }}-<< parameters.python-version >>
          paths:
            - "python_installer"

      - restore_cache:
          name: Restore Python Dependencies Cache
          key: windows_python_installer-python-<< parameters.python-version >>-{{ .Branch }}-py-deps-cache

      - when:
          condition: << pipeline.parameters.agent_version >>
          steps:
            - run:
                name: Change package version to << pipeline.parameters.agent_version >>.
                shell: bash
                command: |
                  echo << pipeline.parameters.agent_version >> > VERSION
      - unless:
          condition: << pipeline.parameters.agent_version >>
          steps:
            - run:
                name: Bump Version
                shell: bash
                command: |
                  # Update agent version to avoid version conflict with current scalyr repository package.
                  # This way we can also correctly assert that the upgrade has worked - if we didn't do
                  # that, from and to version would be the same
                  # NOTE: We can't include git revision as part of the version since it's not a valid
                  # version on Windows.

                  echo "$(cat VERSION).1" > VERSION
                  cat VERSION
      - run:
          name: Build MSI package
          shell: powershell.exe
          command: |
              $Env:WIX = ";C:\wix311;"

              # Make sure step fails on any command failure
              Set-StrictMode -Version Latest
              $ErrorActionPreference = "Stop"

              function ThrowOnNativeFailure {
                if (-not $?)
                {
                    throw 'Native Failure'
                }
              }

              $PSDefaultParameterValues['*:ErrorAction']='Stop'

              C:\Users\circleci\AppData\Local\Programs\Python\Python310\python.exe -m pip install -r win32\windows-build-requirements.txt

              # TODO: This step doesn't correctly exit with non zero on failure
              C:\Users\circleci\AppData\Local\Programs\Python\Python310\python.exe build_package.py win32
              ThrowOnNativeFailure

              mkdir package
              mkdir artifacts

              cp .\ScalyrAgentInstaller-*.msi artifacts/
              mv .\ScalyrAgentInstaller-*.msi package\ScalyrAgentInstaller.msi

              $ErrorActionPreference = "Stop"
              Test-Path -Path package/ScalyrAgentInstaller.msi -PathType Leaf

      - run:
          name: Copy Package With Version in Name
          shell: bash
          command: |
            # NOTE: We preserve two versions of the package as the build artifact. One with the
            # version in the name and one without.
            # This way AMI tests can use one with the static name and if we use it elsewhere (aka
            # if someone wgets a dev package or similar) they immediately know it's a dev version
            # from the name itself.
            export PACKAGE_VERSION="$(cat VERSION)"
            cp package/ScalyrAgentInstaller.msi package/ScalyrAgentInstaller-${PACKAGE_VERSION}.msi

      - save_cache:
          name: Save Python Dependencies Cache
          key: windows_python_installer-python-<< parameters.python-version >>-{{ .Branch }}-py-deps-cache
          paths:
            - C:\Users\circleci\AppData\Local\pip\Cache

      - persist_to_workspace:
          root: package
          paths: ScalyrAgentInstaller.msi

      - store_artifacts:
          path: artifacts

  build-linux-packages-and-installer-script:
    description: "Build deb and rpm packages."
    working_directory: ~/scalyr-agent-2
    docker:
        # NOTE: fpm and git gem depend on Ruby >= 2.3 so we need to use Debian
        # 10 which ships with Ruby 2.5. Jessie (Debian 8) ships with 2.1 which
        # doesn't work anymore with those gems.
        - image: cimg/python:3.6
    environment:
      RELEASE_REPO_NAME: "<< pipeline.parameters.release_repo_name >>"
      RELEASE_REPO_BASE_URL: "<< pipeline.parameters.release_repo_base_url >>"
      RELEASE_AGENT_VERSION: "<< pipeline.parameters.agent_version >>"
    steps:
      - checkout
      - restore_cache:
          key: deps2-tox-{{ .Branch }}-3.6-venv-{{ checksum "dev-requirements.txt" }}

      - run:
          name: Install System Dependencies
          command: |
            sudo apt-key update
            sudo apt update
            sudo apt install -y ruby ruby-dev rubygems rpm build-essential --force-yes
            # Needed to validate rpm package
            sudo apt install -y rpm

            # TODO: looks like fpm upgraded its 'ffi' dependency version, which is now requres newer version of ruby.
            # as a temporaty solution explicitly specify ffi version.
            sudo gem install --no-document ffi:1.14.2 fpm:1.12.0

      - run:
          name: Build packages and install script.
          command: |
            mkdir output
            mkdir artifacts
            mkdir package

            bash  ~/scalyr-agent-2/scripts/circleci/release/build-linux-packages-and-installer-script.sh \
              "$RELEASE_AGENT_VERSION" \
              ./output \
              "$RELEASE_REPO_BASE_URL" \
              "$RELEASE_REPO_NAME" \

            cp output/*.rpm output/*.deb output/installScalyrAgentV2.sh output/RELEASE_VERSION output/scalyr.repo artifacts

            cp artifacts/scalyr-agent-2*.deb package/scalyr-agent-2.deb
            cp artifacts/scalyr-agent-2*.rpm package/scalyr-agent-2.rpm
            cp artifacts/installScalyrAgentV2.sh package/installScalyrAgentV2.sh

      - persist_to_workspace:
          root: package
          paths:
            - scalyr-agent-2.deb
            - scalyr-agent-2.rpm
            - installScalyrAgentV2.sh

      - store_artifacts:
          path: artifacts

  ami-tests-stable-windows:
    circleci_ip_ranges: true # opt into this functionlity for whitelisting purposes
    description: "Run scalyr agent packages install sanity tests for the stable packages from the Scalyr repository."
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.10
    # TODO: Remove resource_class and use default medium one if tests are still
    # failing with large
    resource_class: medium
    steps:
      - ami-tests:
          test_type: "stable"
          test_os: "windows"

  ami-tests-stable-linux:
    circleci_ip_ranges: true # opt into tlinuxhis functionlity for whitelisting purposes
    description: "Run scalyr agent packages install sanity tests for the stable packages from the Scalyr repository."
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.10
    # TODO: Remove resource_class and use default medium one if tests are still
    # failing with large
    resource_class: medium
    steps:
      - ami-tests:
          test_type: "stable"
          test_os: "linux"

  ami-tests-development-windows:
    circleci_ip_ranges: true # opt into this functionlity for whitelisting purposes
    description: "Run scalyr agent packages sanity tests for the new packages which are built on the current revision."
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.10
    # TODO: Remove resource_class and use default medium one if tests are still
    # failing with large
    resource_class: medium
    steps:
      - ami-tests:
          test_type: "development"
          test_os: "windows"

  ami-tests-development-linux:
    circleci_ip_ranges: true # opt into this functionlity for whitelisting purposes
    description: "Run scalyr agent packages sanity tests for the new packages which are built on the current revision."
    working_directory: ~/scalyr-agent-2
    docker:
      - image: cimg/python:3.10
    # TODO: Remove resource_class and use default medium one if tests are still
    # failing with large
    resource_class: medium
    steps:
      - ami-tests:
          test_type: "development"
          test_os: "linux"

workflows:
 version: 2
 static-analysis:
   <<: *skip_release_build_branch_push
   jobs:
     - lint-checks:
         context: scalyr-agent
 unit-tests:
   <<: *skip_release_build_branch_push
   # NOTE: To avoid massive and inflated build matrix, we currently don't run tests under multiple
   # Python 3 versions
   jobs:
     - unittest-27:
         context: scalyr-agent
     - unittest-36:
         context: scalyr-agent
     - unittest-38:
         context: scalyr-agent
     - unittest-38-osx:
         context: scalyr-agent
     - unittest-310-windows:
         context: scalyr-agent
 smoke-tests:
   <<: *skip_release_build_branch_push
   jobs:
     - smoke-standalone-27:
         context: scalyr-agent
     - smoke-standalone-35:
         context: scalyr-agent
     - smoke-standalone-38:
         context: scalyr-agent
     - smoke-standalone-35-rate-limit:
         context: scalyr-agent
      # NOTE: smoke test jobs below still use old smoke tests framework
     - smoke-docker-json:
         context: scalyr-agent
     - smoke-docker-api-raw-logs-disabled:
         context: scalyr-agent
     - smoke-docker-syslog:
         context: scalyr-agent
     - smoke-k8s:
         context: scalyr-agent
     - smoke-monitors-tests:
         context: scalyr-agent
     - sonarcloud-scan:
         requires:
           # NOTE: This is not ideal, but Circle CI doesn't support cross
           # workflow dependencies (we can't wait on unittest-27 here) so we just wait on the
           # slowest jobs
           - smoke-docker-json
           - smoke-docker-api-raw-logs-disabled
           - smoke-docker-syslog
           - smoke-k8s
           - smoke-monitors-tests
 package-tests:
   <<: *skip_release_build_branch_push
   jobs:
     - build-linux-packages-and-installer-script
     - build-windows-package
     - package-test-rpm:
         context: scalyr-agent
         <<: *master_and_release_only
     - package-test-deb:
         context: scalyr-agent
         <<: *master_and_release_only
     - smoke-rpm-package-py2:
         context: scalyr-agent
         requires:
           - package-test-rpm
         <<: *master_and_release_only
     - smoke-rpm-package-py3:
         context: scalyr-agent
         requires:
           - package-test-rpm
         <<: *master_and_release_only
     - smoke-deb-package-py2:
         context: scalyr-agent
         requires:
           - package-test-deb
         <<: *master_and_release_only
     - smoke-deb-package-py3:
         context: scalyr-agent
         requires:
           - package-test-deb
         <<: *master_and_release_only
     - ami-tests-development-windows:
          context: scalyr-agent
          requires:
            - build-windows-package
     - ami-tests-development-linux:
          context: scalyr-agent
          requires:
            - build-linux-packages-and-installer-script
     - ami-tests-stable-windows:
          context: scalyr-agent
          <<: *master_and_release_only
     - ami-tests-stable-linux:
          context: scalyr-agent
          <<: *master_and_release_only
 benchmarks:
   <<: *skip_release_build_branch_push
   jobs:
     - benchmarks-micro-py-27
     - benchmarks-micro-py-35
     - benchmarks-idle-agent-py-27:
         <<: *benchmarks_master_and_release_only
     - benchmarks-idle-agent-py-35:
         <<: *benchmarks_master_and_release_only
     - benchmarks-idle-agent-no-monitors-py-27:
         <<: *benchmarks_master_and_release_only
     - benchmarks-idle-agent-no-monitors-py-35:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-27:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-35:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent-single-growing-log-file-20mb-py-27:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent-single-growing-log-file-20mb-py-35:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent-single-growing-log-file-180mb-py-27:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent_2-growing_logs-monitors-multiprocess-2-worker-20mb-py-35:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-27:
         <<: *benchmarks_master_and_release_only
     - benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-35:
         <<: *benchmarks_master_and_release_only
     # - send-benchmark-results-and-graphs-to-slack:
     #     requires:
     #       - benchmarks-idle-agent-py-27
     #       - benchmarks-idle-agent-py-35
     #       - benchmarks-idle-agent-no-monitors-py-27
     #       - benchmarks-idle-agent-no-monitors-py-35
     #       - benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-27
     #       - benchmarks-loaded-agent-single-50mb-log-file-with-parser-py-35
     #       - benchmarks-loaded-agent-single-growing-log-file-20mb-py-27
     #       - benchmarks-loaded-agent-single-growing-log-file-20mb-py-35
     #       - benchmarks-loaded-agent-single-growing-log-file-180mb-py-27
     #       - benchmarks-loaded-agent_2-growing_logs-monitors-multiprocess-2-worker-20mb-py-35
     #       - benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-27
     #       - benchmarks-loaded-agent-single-50mb-log-file-with-500k-lines-py-35
     #     <<: *benchmarks_master_and_release_only
 weekly-circle-ci-usage-report:
   triggers:
     - schedule:
         cron: "0 0 * * 0"
         filters:
           branches:
             only:
               - master
   jobs:
     - send-circle-ci-usage-report

 hourly-windows-ami-tests:
   triggers:
     - schedule:
         cron: "0 * * * *"
         filters:
           branches:
             only:
               - win_py30_changes
   jobs:
     - ami-tests-development-windows:
         context: scalyr-agent
         requires:
            - build-windows-package
     - build-windows-package
     - build-linux-packages-and-installer-script

 # We run AMI based package install tests which utilize installer script on
 # daily basis.
 # This helps us detect various installer script and other potential upstream
 # issues.
 daily-stable-ami-package-install-tests:
   triggers:
     - schedule:
         cron: "0 2 * * *"
         filters:
           branches:
             only:
               - master
   jobs:
     - ami-tests-stable-windows:
         context: scalyr-agent
     - ami-tests-stable-linux:
         context: scalyr-agent
     - unittest-27:
         context: scalyr-agent
     - unittest-36:
         context: scalyr-agent
     - unittest-38:
         context: scalyr-agent
     - unittest-38-osx:
         context: scalyr-agent
     - unittest-310-windows:
         context: scalyr-agent
     - build-linux-packages-and-installer-script
     - build-windows-package
     - package-test-rpm:
         context: scalyr-agent
     - package-test-deb:
         context: scalyr-agent
     - smoke-rpm-package-py2:
         context: scalyr-agent
         requires:
           - package-test-rpm
     - smoke-rpm-package-py3:
         context: scalyr-agent
         requires:
           - package-test-rpm
     - smoke-deb-package-py2:
         context: scalyr-agent
         requires:
           - package-test-deb
     - smoke-deb-package-py3:
         context: scalyr-agent
         requires:
           - package-test-deb
