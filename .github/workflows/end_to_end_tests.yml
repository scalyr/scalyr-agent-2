name: "Kubernetes End to End Tests"

on:
  push:
  pull_request:
    branches:
      - master
  schedule:
    - cron: '0 4 * * *'

permissions:
  actions: write  # Needed for skip-duplicate-jobs job
  contents: read

jobs:
  # Special job which automatically cancels old runs for the same branch, prevents runs for the
  # same file set which has already passed, etc.
  pre_job:
    name: Skip Duplicate Jobs Pre Job
    runs-on: ubuntu-latest
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
        # Since we allow triggering of this workflow with 'push' and 'pull_request' events,
        # there has to be a duplicated triggering when we push into a branch which has also a PR opened.
        # This job has to skip duplicates in this case, but it's also important, in case of opened PR,
        # to not skip the 'pull_request' event because it has to perform more extra tests, rather that regular 'push'
        # event triggered workflow.
      - name: "Determine which trigger event can not be skipped."
        id: get_events_to_not_skip
        run: |
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo '::set-output name=events_to_not_skip::["workflow_dispatch", "schedule", "pull_request"]'
          else
            echo '::set-output name=events_to_not_skip::["workflow_dispatch", "schedule"]'
          fi

      - id: skip_check
        uses: fkirc/skip-duplicate-actions@f11521568414503656a5af807dc3018c012552c4 # v4.0.0
        with:
          cancel_others: 'true'
          concurrent_skipping: 'same_content'
          do_not_skip: "${{ steps.get_events_to_not_skip.outputs.events_to_not_skip }}"
          github_token: ${{ github.token }}

  coverage:
    runs-on: ubuntu-latest
    if: success() || failure()
    needs:
      - pre_job
      - k8s-smoketest
      - docker-smoketest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
      - name: Setup Python
        uses: actions/setup-python@v4
        id: setup-python
        with:
          python-version: 3.8
      - name: Install pycoverage
        run: pip install coverage==4.5.4
      - name: Download coverage reports
        uses: actions/download-artifact@v3
        with:
          path: reports

      - name: Prepare Coverage Data for codecov.io
        run: |
          coverage combine reports/**/.coverage
          coverage xml -i -o coverage.xml

      - name: Upload Coverage to Codecov.io
        uses: codecov/codecov-action@d9f34f8cd5cb3b3eb79b3e4b5dae3a16df499a70 # pin@v3
        with:
          files: ./coverage.xml
          fail_ci_if_error: true

  # Jobs which performs basic sanity checks for the Kubernetes Monitor and Kubernetes Events Monitor
  k8s_kubernetes_monitor_tests:
    name: Kubernetes Monitors - k8s ${{ matrix.k8s_version.version }}-${{ matrix.k8s_version.runtime}}
    runs-on: ubuntu-20.04
    timeout-minutes: 15

    needs: pre_job
    # NOTE: We always want to run job on master branch
    if: ${{ needs.pre_job.outputs.should_skip != 'true' || (github.ref == 'refs/heads/master' || github.base_ref == 'master') }}

    strategy:
      fail-fast: false
      matrix:
        k8s_version:
          - { "version": "v1.17.17", "driver": "", "runtime": "docker" }
          - { "version": "v1.20.15", "driver": "", "runtime": "docker" }
          - { "version": "v1.21.10", "driver": "", "runtime": "docker" }
          - { "version": "v1.22.7", "driver": "", "runtime": "docker" }
          # NOTE: Using containerd runtime in minikube on  GHA only works with docker driver
          - { "version": "v1.23.4", "driver": "docker", "runtime": "containerd" }
          - { "version": "v1.24.0", "driver": "docker", "runtime": "containerd" }

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup Python 3.8
        uses: actions/setup-python@v4
        id: setup-python
        with:
          python-version: 3.8

      - name: Install Scalyr tool
        run: |
          curl https://raw.githubusercontent.com/scalyr/scalyr-tool/master/scalyr > scalyr
          chmod +x scalyr
          sudo mv scalyr /usr/local/bin

      - name: Setup minikube k8s cluster
        uses: ./.github/actions/setup-minikube-cluster/
        with:
          k8s_version: "${{ matrix.k8s_version.version }}"
          minikube_driver: "${{ matrix.k8s_version.driver }}"
          container_runtime: "${{ matrix.k8s_version.runtime }}"
          github_token: "${{ secrets.GITHUB_TOKEN }}"

      # TODO: Build image as a first job in the workflow and then re-use that image for other jobs
      # to speed up the build and reduce number of redundant builds.
      - name: Build Agent k8s Docker Image
        run: |
          python3 build_package_new.py k8s-debian --tag "local_k8s_image" --platforms linux/amd64
          docker image ls

          # Needed for containerd runtime
          if [ "${{ matrix.k8s_version.runtime }}" = "containerd" ]; then
            minikube image load scalyr-k8s-agent:local_k8s_image
          fi

      # Here we build the dummy container which continously prints data to stdout and stderr
      - name: Build Dummy App Docker Image
        run: |
          docker build -f docker/Dockerfile.docker_monitor_testing_config -t std-printer scripts/
          docker image ls

          # Needed for containerd runtime
          if [ "${{ matrix.k8s_version.runtime }}" = "containerd" ]; then
            minikube image load std-printer:latest
          fi

      # Create pod for our mock std printer container which logs will be ingested by the agent
      - name: Create mock pod
        run: |
          kubectl apply -f tests/e2e/k8s_k8s_monitor/std_printer_deployment.yaml

          sleep 10
          kubectl get pods -A

          export APP_POD_NAME=$(kubectl get pod --namespace=default --selector=app=std-printer -o jsonpath="{.items[0].metadata.name}")
          echo "APP_POD_NAME=${APP_POD_NAME}" >> ${GITHUB_ENV}
          echo "APP_POD_NAME=${APP_POD_NAME}"

          echo ""
          kubectl logs "${APP_POD_NAME}"
          echo ""

      - name: Create scalyr-agent-2 daemonset
        uses: ./.github/actions/install-k8s-agent/
        with:
          scalyr_server: "agent.scalyr.com"
          scalyr_api_key: "${{ secrets.SCALYR_PROD_CLOUDTECH_TESTING_WRITE_TOKEN }}"
          scalyr_cluster_name: "${K8S_CLUSTER_NAME}"
          scalyr_k8s_events_disable: "false"
          main_yaml_path: "tests/e2e/scalyr-agent-2-daemonset.yaml"

      - name: Verify data has been ingested
        timeout-minutes: 14
        env:
          # Needed for scalyr-tool
          scalyr_readlog_token: "${{ secrets.SCALYR_CLOUDTECH_TESTING_DEV_SCALYR_READ_API_KEY }}"
          SCALYR_AGENT_POD_NAME: "${{ env.SCALYR_AGENT_POD_NAME }}"
          K8S_NODE_NAME: "${{ env.K8S_NODE_NAME }}"
        run: |
          export RETRY_ATTEMPTS="14"
          export SLEEP_DELAY="10"

          # Verify agent is running
          echo "Agent running checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Starting scalyr agent..."'

          # Verify Kubernetes monitor is running
          echo "Kubernetes Monitor running checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "kubernetes_monitor parameters: ignoring namespaces: "'
          echo ""

          # Verify Kubernetes events monitor is running
          echo "Kubernetes events monitor running checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Starting monitor kubernetes_events_monitor"'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Acting as Kubernetes event leader"'
          echo ""

          # Verify initial std-printer pod data has been ingested

          # 1. First we want for some data to be ingested using "log.config.scalyr.com/attributes.parser"
          # annotation set as part of the deployment YAML.
          # After a while, we change that dynamically using kubectl and verify that this change has
          # been correctly picked up by the agent.
          sleep 20

          echo "Initial pod ingested data checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" app="std-printer" parser="test-parser-1" stream="stdout" "stdout: line 2"'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" app="std-printer" parser="test-parser-1" stream="stderr" "stderr: line 2"'
          echo ""

          kubectl describe pod ${APP_POD_NAME}
          kubectl annotate --overwrite pods ${APP_POD_NAME} log.config.scalyr.com/attributes.parser="changed"
          kubectl describe pod ${APP_POD_NAME}

          # Give agent some time to pick up the annotation change (by default we poll every 30 seconds
          # for pod metadata changes, but we use lower value for the tests)
          sleep 15

          echo ""
          echo "Post annotation change data checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" app="std-printer" parser="changed" stream="stdout" "stdout: line"'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" app="std-printer" parser="changed" stream="stderr" "stderr: line"'
          echo ""

          # Verify Kubernetes Events Monitor events are ingested
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/kubernetes_events.log" $parser="k8sEvents" "\"kind\":\"Event\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/kubernetes_events.log" $parser="k8sEvents" "\"kind\":\"Pod\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/kubernetes_events.log" $parser="k8sEvents" "involvedObject"'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/kubernetes_events.log" $parser="k8sEvents" "NodeReady"'

          agent_status=$(kubectl --namespace=scalyr exec -i ${SCALYR_AGENT_POD_NAME} --container scalyr-agent -- scalyr-agent-2 status -v)
          k8s_event_log_files_number=$(echo "$agent_status" | grep -c 'Path /var/log/scalyr-agent-2/kubernetes_events.log: copied')

          if [ "$k8s_event_log_files_number" != 1 ]; then
            echo "Kubernetes event monitor log has to be handled by the agent 1 time, but it got ${k8s_event_log_files_number}"
            exit 1
          fi

      - name: Notify Slack on Failure
        # NOTE: github.ref is set to pr ref (and not branch name, e.g. refs/pull/28/merge) for pull
        # requests and that's why we need this special conditional and check for github.head_ref in
        # case of PRs
        if: ${{ failure() && (github.ref == 'refs/heads/master' || github.head_ref == 'master') }}
        uses: act10ns/slack@87c73aef9f8838eb6feae81589a6b1487a4a9e08 # v1.6.0
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        with:
          status: ${{ job.status }}
          steps: ${{ toJson(steps) }}
          channel: '#eng-dataset-cloud-tech'

  k8s_open_metrics_monitor_tests:
    name: OpenMetrics Monitor - k8s ${{ matrix.k8s_version.version }}-${{ matrix.k8s_version.runtime}}
    runs-on: ubuntu-20.04
    timeout-minutes: 15

    needs: pre_job
    # NOTE: We always want to run job on master branch
    if: ${{ needs.pre_job.outputs.should_skip != 'true' || ( github.ref == 'refs/heads/master' || github.base_ref == 'master' ) }}

    strategy:
      fail-fast: false
      matrix:
        k8s_version:
          - { "version": "v1.17.17", "driver": "", "runtime": "docker" }
          - { "version": "v1.20.15", "driver": "", "runtime": "docker" }
          - { "version": "v1.21.10", "driver": "", "runtime": "docker" }
          - { "version": "v1.22.7", "driver": "", "runtime": "docker" }
          # NOTE: Using containerd runtime in minikube on  GHA only works with docker driver
          - { "version": "v1.23.4", "driver": "docker", "runtime": "containerd" }
          - { "version": "v1.24.0", "driver": "docker", "runtime": "containerd" }

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup Python 3.8
        uses: actions/setup-python@v4
        id: setup-python
        with:
          python-version: 3.8

      - name: Install Scalyr tool
        run: |
          curl https://raw.githubusercontent.com/scalyr/scalyr-tool/master/scalyr > scalyr
          chmod +x scalyr
          sudo mv scalyr /usr/local/bin

      - name: Setup minikube k8s cluster
        uses: ./.github/actions/setup-minikube-cluster/
        with:
          k8s_version: "${{ matrix.k8s_version.version }}"
          minikube_driver: "${{ matrix.k8s_version.driver }}"
          container_runtime: "${{ matrix.k8s_version.runtime }}"
          github_token: "${{ secrets.GITHUB_TOKEN }}"

      - name: Build Agent k8s Docker Image
        run: |
          python3 build_package_new.py k8s-debian --tag "local_k8s_image" --platforms linux/amd64
          docker image ls

          # Needed for containerd runtime
          if [ "${{ matrix.k8s_version.runtime }}" = "containerd" ]; then
            minikube image load scalyr-k8s-agent:local_k8s_image
          fi

      # Here we build the dummy Java app image which exposes JMX metrics via exporter
      - name: Build Test Java App Docker Image
        run: |
          pushd tests/e2e/k8s_om_monitor/java-hello-world
          docker build -t java-hello-world .
          popd

          docker image ls

          # Needed for containerd runtime
          if [ "${{ matrix.k8s_version.runtime }}" = "containerd" ]; then
            minikube image load java-hello-world:latest
          fi

      # Create mock pods and exporters which will be scrapped by the monitor
      - name: Create mock pods and exporters
        run: |
          kubectl create namespace monitoring

          # 1. node exporter pod
          kubectl apply -f tests/e2e/k8s_om_monitor/node_exporter.yaml

          # 2. kube state metrics deployment
          kubectl apply -k tests/e2e/k8s_om_monitor/kube-state-metrics/

          # 3. Install dummy java app container with jmx exporter side
          kubectl apply -f tests/e2e/k8s_om_monitor/java_app_deployment.yaml

          sleep 20
          kubectl get pods -A

      - name: Create scalyr-agent-2 daemonset
        uses: ./.github/actions/install-k8s-agent/
        with:
          scalyr_server: "agent.scalyr.com"
          scalyr_api_key: "${{ secrets.SCALYR_PROD_CLOUDTECH_TESTING_WRITE_TOKEN }}"
          scalyr_cluster_name: "${K8S_CLUSTER_NAME}"
          main_yaml_path: "tests/e2e/k8s_om_monitor/scalyr-agent-2-daemonset.yaml"
          # Monitor is not enabled by default yet since it's still in preview and testing phase so
          # we expliticly enable it here
          extra_yaml_paths: "tests/e2e/k8s_om_monitor/scalyr-agent-extra-config-configmap.yaml"

      - name: Verify data has been ingested
        timeout-minutes: 14
        env:
          # Needed for scalyr-tool
          scalyr_readlog_token: "${{ secrets.SCALYR_CLOUDTECH_TESTING_DEV_SCALYR_READ_API_KEY }}"
          SCALYR_AGENT_POD_NAME: "${{ env.SCALYR_AGENT_POD_NAME }}"
          K8S_NODE_NAME: "${{ env.K8S_NODE_NAME }}"
          K8S_CLUSTER_NAME: "${{ env.K8S_CLUSTER_NAME }}"
        run: |
          export RETRY_ATTEMPTS="14"
          export SLEEP_DELAY="10"

          # Verify agent is running
          echo "Agent running checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Starting scalyr agent..."'

          # Verify monitor is running
          echo "Monitor running checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "Found 3 URL(s) to scrape for node"'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile="/var/log/scalyr-agent-2/agent.log" "There are currently 3 dynamic and 2 static open metrics monitors running"'
          echo ""

          # Kubernetes API metrics (static monitor)
          echo "Kubernetes API metrics monitor checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-kubernetes-api-metrics.log" "process_max_fds 1000000 k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-kubernetes-api-metrics.log" "process_open_fds "'

          # Kubernetes API cAdvisor metrics (static monitor)
          echo "Kubernetes API cAdvisor metrics monitor checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-kubernetes-api-cadvisor-metrics" "machine_cpu_cores 2"'
          MINIMUM_RESULTS=2 ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-kubernetes-api-cadvisor-metrics" "container_cpu_load_average_10s "'
          # Verify locally calculated rate metrics
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-kubernetes-api-cadvisor-metrics" "container_cpu_usage_seconds_total_rate "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-kubernetes-api-cadvisor-metrics" "container_network_receive_bytes_total_rate "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-kubernetes-api-cadvisor-metrics" "container_network_transmit_bytes_total_rate "'

          # 2. Verify node exporter metrics
          echo "Node exporter metrics monitor checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "process_max_fds "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "process_open_fds "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "node_vmstat_pswpin "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "node_vmstat_pswpout "'
          # Verify locally calculated rate metrics
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "node_cpu_seconds_total_rate "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "node_network_transmit_bytes_total_rate "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "node_network_receive_bytes_total_rate "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "node_disk_read_bytes_total_rate "'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'-node-exporter-" "node_disk_written_bytes_total_rate "'

          # 3. Verify kube state event metrics
          echo "Kube state events metrics monitor checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "kube-state-metrics" "kube_storageclass_labels 1 k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\" storageclass=\"standard\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "kube-state-metrics" "kube_secret_type 1 k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\" namespace=\"scalyr\" secret=\"scalyr-api-key\" type=\"Opaque\""'

          # 4. Verify java app JMX metrics
          echo "Java JMX metrics events metrics monitor checks"
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "java-hello-world" "jmx_scrape_error 0.0 app=\"java-hello-world\" app_instance=\"java-hello-world-1\" attribute1=\"value1\" k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "java-hello-world" "jmx_scrape_cached_beans 0.0 app=\"java-hello-world\" app_instance=\"java-hello-world-1\" attribute1=\"value1\" k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "java-hello-world" "jvm_info 1.0 app=\"java-hello-world\" app_instance=\"java-hello-world-1\" attribute1=\"value1\" k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\" runtime="'

          # Client side calculated per second rate metrics
          # NOTE: There is no easy way to assert on the actual rate metric value here (we have unit tests for that)
          # so we just assert that the metric is present.
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "java-hello-world" "jvm_threads_started_total_rate" "app=\"java-hello-world\" app_instance=\"java-hello-world-1\" attribute1=\"value1\" k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "java-hello-world" "jvm_memory_pool_allocated_bytes_total_rate" "app=\"java-hello-world\" app_instance=\"java-hello-world-1\" attribute1=\"value1\" k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\""'
          ./scripts/cicd/scalyr-query.sh '$serverHost="'${SCALYR_AGENT_POD_NAME}'" $logfile contains "openmetrics_monitor-'${K8S_NODE_NAME}'" $logfile contains "java-hello-world" "process_cpu_seconds_total_rate" "app=\"java-hello-world\" app_instance=\"java-hello-world-1\" attribute1=\"value1\" k8s-cluster=\"'${K8S_CLUSTER_NAME}'\" k8s-node=\"'${K8S_NODE_NAME}'\""'

      - name: Notify Slack on Failure
        # NOTE: github.ref is set to pr ref (and not branch name, e.g. refs/pull/28/merge) for pull
        # requests and that's why we need this special conditional and check for github.head_ref in
        # case of PRs
        if: ${{ failure() && (github.ref == 'refs/heads/master' || github.head_ref == 'master') }}
        uses: act10ns/slack@87c73aef9f8838eb6feae81589a6b1487a4a9e08 # v1.6.0
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        with:
          status: ${{ job.status }}
          steps: ${{ toJson(steps) }}
          channel: '#eng-dataset-cloud-tech'

  k8s-smoketest:
    runs-on: ubuntu-20.04
    needs: pre_job
    if: ${{ needs.pre_job.outputs.should_skip != 'true' || (github.ref == 'refs/heads/master' || github.base_ref == 'master') }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
      - name: Setup Python 3.8
        uses: actions/setup-python@v4
        id: setup-python
        with:
          python-version: 3.8
          cache: 'pip'
      - name: Install Python Dependencies
        run: |
          pip install -r dev-requirements.txt
          pip install "apache-libcloud==3.4.1"

      - name: Setup minikube k8s cluster
        uses: ./.github/actions/setup-minikube-cluster/
        with:
          k8s_version: v1.22.0
          minikube_driver: ""
          container_runtime: "docker"
          github_token: "${{ secrets.GITHUB_TOKEN }}"

      - name: Run Tests (with coverage)
        env:
          CIRCLE_BUILD_NUM: ${{ github.run_number }}
          SCALYR_SERVER: https://agent.scalyr.com
          SCALYR_API_KEY: ${{ secrets.SCALYR_API_KEY }}
          READ_API_KEY: ${{ secrets.SCALYR_READ_API_KEY }}
        run: |
          source ./.circleci/smoketest_k8s.sh scalyr/scalyr-agent-ci-unittest:4 150 no_delete_existing_k8s_objs

      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: k8s-smoketest
          path: |
            .coverage
        if: ${{ success() || failure() }}

      - name: Notify Slack on Failure
        # NOTE: github.ref is set to pr ref (and not branch name, e.g. refs/pull/28/merge) for pull
        # requests and that's why we need this special conditional and check for github.head_ref in
        # case of PRs
        if: ${{ failure() && (github.ref == 'refs/heads/master' || github.head_ref == 'master') }}
        uses: act10ns/slack@87c73aef9f8838eb6feae81589a6b1487a4a9e08 # v1.6.0
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        with:
          status: ${{ job.status }}
          steps: ${{ toJson(steps) }}
          channel: '#eng-dataset-cloud-tech'

  docker-smoketest:
    name: Docker Smoketest - ${{ matrix.variant.log_mode }}
    needs: pre_job
    if: ${{ needs.pre_job.outputs.should_skip != 'true' || (github.ref == 'refs/heads/master' || github.base_ref == 'master') }}
    runs-on: ubuntu-20.04
    strategy:
      fail-fast: false
      matrix:
        variant:
          - log_mode: json
            timeout: 150
          - log_mode: syslog
            timeout: 150
          - log_mode: api
            timeout: 200
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
      - name: Setup Python 3.8
        uses: actions/setup-python@v4
        id: setup-python
        with:
          python-version: 3.8
          cache: 'pip'
      - name: Install Python Dependencies
        run: |
          pip install -r dev-requirements.txt
          pip install "apache-libcloud==3.4.1"
      - name: Run Tests (with coverage)
        env:
          CIRCLE_BUILD_NUM: ${{ github.run_number }}
          SCALYR_SERVER: https://agent.scalyr.com
          SCALYR_API_KEY: ${{ secrets.SCALYR_API_KEY }}
          READ_API_KEY: ${{ secrets.SCALYR_READ_API_KEY }}
        run: |
          source ./.circleci/smoketest_docker.sh scalyr/scalyr-agent-ci-unittest:4 docker-${{ matrix.variant.log_mode }} ${{ matrix.variant.timeout }}

      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: docker-smoketest-${{ matrix.variant.log_mode }}
          path: |
            .coverage
        if: ${{ success() || failure() }}

      - name: Notify Slack on Failure
        # NOTE: github.ref is set to pr ref (and not branch name, e.g. refs/pull/28/merge) for pull
        # requests and that's why we need this special conditional and check for github.head_ref in
        # case of PRs
        if: ${{ failure() && (github.ref == 'refs/heads/master' || github.head_ref == 'master') }}
        uses: act10ns/slack@87c73aef9f8838eb6feae81589a6b1487a4a9e08 # v1.6.0
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        with:
          status: ${{ job.status }}
          steps: ${{ toJson(steps) }}
          channel: '#eng-dataset-cloud-tech'

  # Runs agent from it source and performs some basic sanity checks.
  agent-source-tests:
    runs-on: ${{ matrix.os }}
    needs: pre_job
    if: ${{ needs.pre_job.outputs.should_skip != 'true' || (github.ref == 'refs/heads/master' || github.base_ref == 'master') }}
    container: ${{ matrix.container }}
    strategy:
      matrix:
        os: [ "macos-11", "ubuntu-18.04" ]
        python-version: [ "3.7.13" ]
        # Uncomment when windows platform and service related issues are fixed.
    #        include:
    #          - os: "windows-2019"
    #            python-version: "3.7.9"


    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Install python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Perform the deployment of the test environment
        uses: ./.github/actions/perform-deployment
        with:
          deployment-name: "test_environment"

      - name: Run tests
        shell: bash
        run: |
          python3 -m pytest  tests/end_to_end_tests/test_from_source/test_from_source.py \
            --scalyr-api-key ${{ secrets.SCALYR_PROD_CLOUDTECH_TESTING_WRITE_TOKEN }} \
            --scalyr-api-read-key ${{ secrets.SCALYR_CLOUDTECH_TESTING_DEV_SCALYR_READ_API_KEY }} \
            --test-session-suffix ${{ github.run_id }}-${{ github.run_attempt }}


